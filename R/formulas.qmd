---
title: "Location-scale Meta-regression as a Tool to Capture Large-scale Changes in Biological and Methodological Heterogeneity"
format: html
editor: visual
---

# Outline

1.  Introudction

2.  Theory

2.1 Random-effects meta-analysis and meta-regression

2.2 Location-scale meta-regression

2.3 Multilevel location-scale meta-regression (MLSM)

2.4 Extending the idea of heterogeneity in location-scale models

2.5 Phylogenetic location-scale meta-regression

2.6 Modeling publication bias in location-scale models

3.  Illustrative examples

3.1 An example for a categorical moderator on the scale part

Using brms in R

Pottier, P., Burke, S., Zhang, R. Y., Noble, D. W., Schwanz, L. E., Drobniak, S. M., & Nakagawa, S. (2022). Developmental plasticity in thermal tolerance: Ontogenetic variation, persistence, and future directions. Ecology Letters, 25(10), 2245-2268.

where they find variance is much higher aquatic organisms than terrestrial organisms

3.2 methodological categorical varaible ---

TODO - we need to find this - try to find a paper that has a methodological moderator on the scale part

3.3 An example for a continuous moderator on the scale part

Midolo G, De Frenne P, Holzel N, Wellstein C. Global patterns of intraspecific leaf trait responses to elevation. Global Change Biol. 2019;25(7):2485–98.

3.4 Deteching different types of publication biases - small study effect, time-lag bias, and protous effect

TODO - find a paper that has all three publication biases

................................................................

Where they find variance in effect sizes increased along the gradient

4.  Discussion

# Some ideas and formulas

## Location-scale meta-analysis

-   Heterogeneity is extremely high in almost all ecological and evolutionary meta-analyses.
-   Indeed the main main of such meta-analyses is to quantify the heterogeneity and to understand the sources of heterogeneity.
-   Yet, the current methods are limited in their ability to quantify and understand the heterogeneity, assuming homoscadastiity
-   Therefore, we propose a new method that can quantify and understand the heterogeneity by introducing location-sclae meta-regression analyses.
-   Although such locaiton-scale models have been used in emprical studies in ecology and evolution, we are yet unaware location-scale models are applied to ecological and evolutionary meta-analyses.
-   We point out location-scale models are particular useful and relevant, even more than emprical studies, as meta-analyses are often based on a wide range of studies that are conducted in different conditions and with different methods, leading to not only high heterogeneity but also different variances amoing different levels in categorical moderators (i.e., heteroscadasticity).
-   Indeed, more than 80% of moderators in ecological and evolutionary meta-analyses are categorical, which are likely to have different variances among different levels.
-   Our method can reassess all previous meta-regression analyses, provding new insights into the underlying heterogeneity and therefore, enrching our understanding of pressing ecolgoical and enviromental issues as well as the biological world.

## Location-scale random-effects model (2)

$$
y_i = \beta_0^{(l)} +  u_{j[i]}^{(l)} + e_i^{(l)} + m_i^{(l)},
\label{eq:ma-location}
$$
and 
$$
\ln(\sigma_{e_i}) = \beta_0^{(s)} + u_{j[i]}^{(s)}.
\label{eq:ma-scale}
$$



### random-effects meta-analysis and meta-regression (2.1)

$$
y_{i} = \beta_0 + e_i + m_i
$$

$yi$ effect size, ... $beta_0$ is the meta-analytic mean (intercept), $e_i$ is the effect-size level effect (the between-study effect), and $m_i$ is the sapling error (asumming within-study variance is zero or part of sampling error).

$$
e_i \sim \mathcal{N}(\mathbf{0}, \sigma_{e}^{2})
$$

$$
m_i \sim \mathcal{N}(\mathbf{0}, \sigma_{m_i}^{2})
$$

$\sigma_{m_i}^{2}$ is the sampling error variance - we use the plug-in value. For example for Zr, we use $\frac{1}{n_{i}-3}$ where $n$ is the sample size used to obtain effect size $y_i$

$$
y_{i} = \beta_0 + \beta_1 x_{1i} + ... +  \beta_p x_{pi} +  e_i + m_i
$$

### location-scale meta-regression (2.2)

$$
y_{i} = \beta_0^{(l)} + \beta_1^{(l)} x_{1i} + ... + \beta_p x_{pi} +  e_i^{(l)} + m_i^{(l)}
$$

$$
e_i^{(l)} \sim \mathcal{N}(\mathbf{0}, \sigma_{e_i(l)}^{2})
$$

$$
\ln({\sigma_{e_i}}) = \beta_0^{(s)} + \beta_1^{(s)} x_{1i} + ... + \beta_p^{(s)} x_{pi} 
$$

$$
m_i \sim \mathcal{N}(\mathbf{0}, \mathbf{V})
$$

$\mathbf{V}$ is a block diagnoal matrix

For example, the part of study 1's with 3 effect sizes where first two effect sizes are correlated

$$
\mathbf{V_1} = \begin{pmatrix}
\sigma_{m_1}^{2} & \rho_{m} \sigma_{m_1} \sigma_{m_2} & 0 \\
\rho_{m} \sigma_{m_1} \sigma_{m_2} & \sigma_{m_2}^{2} & 0 \\
0 & 0 & \sigma_{m_3}^{2}
\end{pmatrix}
$$

One can you the rubst variance estimator instead of V as $\rho_{m}$ is often unknown (although often assumed to be 0.5 or 0.8)

## Mulitlevel location-scale meta-analysis (MLSM) (2.3)

$$
y_{i} = \beta_0^{(l)} + \beta_1^{(l)} x_{1i} + ... + \beta_p^{(l)} x_{pi} + u_{j[i]}^{(l)} + e_i^{(l)}
$$

$$
u_j^{(l)} \sim \mathcal{N}(\mathbf{0}, \sigma_{u(l)}^{2})
$$

### without the random effect in the scale part

$$
\ln({\sigma_{e_i}}) = \beta_0^{(s)} + \beta_1^{(s)} x_{1i} + ... + \beta_p^{(s)} x_{pi} 
$$

### with the random effect in the scale part

$$
\ln({\sigma_{e_i}}) = \beta_0^{(s)} + \beta_1^{(s)} x_{1i} + ... + \beta_p^{(s)} x_{pi} +  u_i^{(l)} 
$$

$$
\begin{pmatrix}
u_j^{(l)} \\
u_j^{(s)}
\end{pmatrix}
\sim \mathcal{N} \left(
\begin{pmatrix}
0 \\
0
\end{pmatrix},
\begin{pmatrix}
\sigma_{u(l)}^{2} & \rho_{u} \sigma_{u(l)} \sigma_{u(s)} \\
\rho_{u} \sigma_{u(l)} \sigma_{u(s)} & \sigma_{u(s)}^{2}
\end{pmatrix}
\right)
$$

Correlation between the location and scale random effects is $\rho_{u}$ is expected to be zero yet if we have a positve correlation it means that the studies with higher effect sizes have higher variances - indicating publcation bias (Fig XXX) - see

## Extending the idea of heterogeneity in location-scale models (2.4)

$$
CV_{H}^{(l)} = \frac{\bar\sigma_{u(l)}}{\sqrt{E(y_i)}}
$$

$$
CV_{H}^{(s)} = \sqrt{\exp(\sigma_{u(s)}^2) - 1}
$$

total variance idea (not that useful here)

## Modeling publication bias in location-scale models (2.5)

### Egger regression & precision-effect estimate with standard error (PEESE), and PET-PEESE

$$
y_{i} = \beta_0 + \beta_1 \sqrt{1/\tilde{n_i}} + u_{j[i]} + e_i
$$ $$
y_{i} = \beta_0 + \beta_1 \left(1/\tilde{n_i} \right) + u_{j[i]} + e_i
$$ When β1 is significant, we conclude there exists a small-study effect (in terms of a funnel plot, this is equivalent to significant funnel asymmetry). Then, we fit 2nd Eq and we look at the intercept β0 , which will be a bias-corrected overall estimate \[note that β0 in 1st Eq provides less accurate estimates when non-zero overall effects exist

### Time-lag effect (decline effect)

$$
y_{i} = \beta_0 + \beta_1 \ c(year_i)+ u_{j[i]} + e_i
$$

### putting all togetehr

$$
y_{i} = \beta_0 + \beta_1 \sqrt{1/\tilde{n_i}} +  \beta_2 c(year_i) + ... + \beta_p x_{pi} + u_{j[i]}+ e_i
$$

### location-scale version

$$
y_i = \beta_0^{(l)} + \beta_1^{(l)} \sqrt{1/\tilde{n_i}} +  \beta_2^{(l)} c(year_i) + ... + \beta_p^{(l)} x_{pi} + u_{j[i]}^{(l)} + e_i^{(l)}
$$ sig $\beta_1^{(l)}$ = small-study effect and sig $\beta_2^{(l)}$ = decline effect

Now the scale part

$$
\ln({\sigma_{e_i}}) = \beta_0^{(s)} + \beta_1^{(s)} \sqrt{1/\tilde{n_i}} +  \beta_2^{(s)} c(year_i) + ... + \beta_p^{(s)} x_{pi}
$$ sig \$ \beta\_1\^{(s)}\$ is heterogeneity in small studies (often heterogenity increases with SE\* = $\sqrt{1/\tilde{n_i}}$ increases) and sig \$ \beta\_2\^{(s)}\$ is heterogeneity in decline effect = it is known as proteous effects (usually variance declines over time)

## Phylogenetic location-scale meta-regression (2.6)

$$
y_{i} = \beta_0^{(l)} + \beta_1^{(l)} x_{1i} + ... + \beta_p^{(l)} x_{pi}
+ a_{k[i]}^{(l)} + s_{k[i]}^{(l)} + u_i^{(l)} + e_i^{(l)}
$$

$$
a_k^{(l)} \sim \mathcal{N}(\mathbf{0}, \sigma_{k(l)}^{2} \mathbf{A})
$$

$$
s_k^{(l)} \sim \mathcal{N}(\mathbf{0}, \sigma_{s(l)}^{2})
$$

$$
\ln({\sigma_{e_i}}) = \beta_0^{(s)} + \beta_1^{(s)} x_{1i} + ... + \beta_p^{(s)} x_{pi}
$$

## Instructions (we are aiming to publish this paper in Global Change Biology)

Technical Advances present exciting new research tools, methods, and techniques, including new modelling approaches, and should include a detailed description of the methodological design and discussion of how this technique improves the study of global change biology. GCB has a wide readership; accordingly the technical advance must be broadly applicable. Papers describing methods that apply to one species or system are unlikely to meet our criteria unless authors are able to show that their methods can be generalized. The main body word limit is 4000 words (Introduction, Materials and Methods, Results & Discussion, and Acknowledgements). Formatting is standard (see Formatting Instructions, below) except that Results and Discussion may be combined. These are peer reviewed. Decisions are made by the Editors.

GCB no longer has strict formatting requirements for initial submissions, but all manuscripts must contain the essential elements required during submission:

```         
Title
Running Title: A short running title of less than 45 characters including spaces
List of Authors: The full names of the authors. As part of the journal’s commitment to supporting authors at every step of the publishing process, the journal requires the submitting author (only) to provide an ORCID iD when submitting a manuscript. This takes around 2 minutes to complete. Find more information here.
Institutional affiliations: All author's institutional affiliations where the work was conducted, with a footnote for the author’s present address if different from where the work was conducted; where authors have different addresses, use numbered superscripts to refer to each address provided.
Contact Information Corresponding author’s telephone, and email details
Abstract: Limited to 300 words. 
Keywords: 6-10 keywords
```

GCB's content often includes regional, national, continental or global maps. We recognize there are disputes over borders and territories, which may be directly relevant for authors when describing their research. Any statements in research papers that declare that the maps published in these represent the borders of a country, can cause difficulties for GCB and Wiley with the country in question and its national laws. To avoid this, on any map that shows boundaries, please add a note clearly stating that "map lines delineate study areas and do not necessarily depict accepted national boundaries". If a perceived dispute or complaint is raised, our editorial team will attempt to find a resolution that works for all parties. Ultimately, the final decision on content is an editorial matter, and will rest with the journal Editors which, where necessary, will be in consultation with the Publisher.

## Notes...

Heterogeneity in ecological and evolutionary meta-­ analyses: its magnitude and implications

Meta-­ analysis is the gold standard for synthesis in ecology and evolution. Together with estimating overall effect magnitudes, meta-­ analyses estimate differences between effect sizes via heterogeneity statistics. It is widely hypothesized that heterogeneity will be present in ecological/evolutionary meta-­ analyses due to the system-­ specific nature of biological phenomena. Despite driving recommended best practices, the generality of heterogeneity in ecological data has never been systematically reviewed. We reviewed 700 studies, finding 325 that used formal meta-­ analysis, of which total heterogeneity was reported in fewer than 40%. We used second-­ order meta-­ analysis to collate heterogeneity statistics from 86 studies. Our analysis revealed that the median and mean heterogeneity, expressed as I2, are 84.67% and 91.69%, respectively. These estimates are well above “high” heterogeneity (i.e., 75%), based on widely adopted benchmarks. We encourage reporting heterogeneity in the forms of I2 and the estimated variance components (e.g., τ2) as standard practice. These statistics provide vital insights in to the degree to which effect sizes vary, and provide the statistical support for the exploration of predictors of effect-­ size magnitude. Along with standard meta-­ regression techniques that fit moderator variables, multi-­ level models now allow partitioning of heterogeneity among correlated (e.g., phylogenetic) structures that exist within data.

########## 

1120427AMPXXX10.1177/25152459221120427Stanley et al.Advances in Methods and Practices in Psychological Science research-article2022 General Article ASSOCIATION FOR PSYCHOLOGICAL SCIENCE Beyond Random Effects: When Small-Study Findings Are More Heterogeneous Advances in Methods and Practices in Psychological Science July-September 2022, Vol. 5, No. 4, pp. 1­ –11 © The Author(s) 2022 Article reuse guidelines: sagepub.com/journals-permissions DOI: 10.1177/25152459221120427 https://doi.org/10.1177/25152459221120427 www.psychologicalscience.org/AMPPS T. D. Stanley1 , Hristos Doucouliagos1, and John P. A. Ioannidis2 1Department of Economics, Deakin University, Victoria, Australia, and 2Department of Medicine, Stanford University, Stanford, California Abstract New meta-regression methods are introduced that identify whether the magnitude of heterogeneity across study findings is correlated with their standard errors. Evidence from dozens of meta-analyses finds robust evidence of this correlation and that small-sample studies typically have higher heterogeneity. This correlated heterogeneity violates the random- effects (RE) model of additive and independent heterogeneity. When small studies not only have inadequate statistical power but also high heterogeneity, their scientific contribution is even more dubious. When the heterogeneity variance is correlated with the sampling-error variance to the degree we find, simulations show that RE is dominated by an alternative weighted average, the unrestricted weighted least squares (UWLS). Meta-research evidence combined with simulations establish that UWLS should replace RE as the conventional meta-analysis summary of psychological research. Keywords meta-analysis, heterogeneity, small samples, meta-regression, random effects, open data, open materials, preregistered Received 3/15/22; Revision accepted 7/30/22 Meta-analysis is sometimes seen to be at the top of the “pyramid of evidence,” and random effects (RE) is the canonical meta-analysis model of psychological research (Ioannidis, 2016; Owens et al., 2010). Large-scale sur- veys and preregistered multilab replications (PMRs) have revealed that publication-selection bias, high het- erogeneity, and low statistical power are the central challenges to the credibility of psychological research (Fraley & Vazire, 2014; Klein et al., 2018; Open Science Collaboration, 2015; Stanley et al., 2018, 2022). Simula- tion studies establish that RE typically produce large biases and high rates of false positives when there is publication-selection bias (Bom & Rachinger, 2019; Carter et al., 2018; Henmi & Copas, 2010; Stanley, 2017; Stanley & Doucouliagos, 2014, 2015; Stanley et al., 2017; van Assen & van Aert, 2015). RE’s large biases and high rates of false positives are corroborated in applications when RE results are compared with PMRs (Kvarven et al., 2020). The central purpose of this article is to demonstrate that the unrestricted weighted least squares (UWLS) weighted average should routinely replace RE in psychology meta-analyses, regardless of whether there is publication bias. If, as we show below, small-sample studies are more heterogeneous, then three major challenges to psy- chology (heterogeneity, low power, and publication- selection bias) emanate largely from a single source. Furthermore, when heterogeneity is correlated with a study’s standard errors, we show that RE estimates are dominated, statistically, by an alternative meta-analysis weighted average—the UWLS (Stanley & Doucouliagos, 2015, 2017). Unlike RE, UWLS better accommodates cor- related heterogeneity because it is built on a model of multiplicative heterogeneity in which heterogeneity is proportional to the variance of each study. To make this case, we need to show that UWLS is expected to have superior statistical properties relative Corresponding Author: T. D. Stanley, Department of Economics, Deakin University, Victoria, Australia Email: tom.stanley1\@deakin.edu.au Creative Commons NonCommercial CC BY-NC: This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 License (https://creativecommons.org/licenses/by-nc/4.0/), which permits noncommercial use, reproduction, and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage). 2 Stanley et al. to RE even when there is no publication bias. Our simu- an area of research and across many meta-regressions lations show that if standard errors and heterogeneity are when combined into a meta-meta-regression. If hetero- correlated in a meta-analysis, then UWLS will dominate geneity is correlated with standard errors, the RE model RE in all cases, with or without publication bias (see Table is no longer valid because it assumes that random het- 3). But what evidence is there that standard error and erogeneity is independent of sampling errors. We applied heterogeneity are typically correlated in an area of psy- these new meta-regression methods to a preregistered chological research? We offer preregistered meta-research group of 53 meta-analyses and found clear and robust evidence that standard errors and heterogeneity are typi- evidence that heterogeneity and standard errors are gen- cally correlated within a psychology meta-analysis and erally correlated in psychology. Finally, we offer new across dozens of meta-analyses. However, before we can simulations grounded on the correlation revealed by this conduct this meta-meta-analysis and gather evidence of meta-research evidence that shows UWLS statistically widespread correlation of standard error with heterogene- dominating RE whether or not there is publication-selec- ity, we must first introduce the meta-regression tests (vari- tion bias. These results have substantial implications for ance ratio meta-regression analysis \[VR-MRA\]) that can practice because they compel the replacement of RE by identify whether standard errors and heterogeneity are in UWLS as the conventional method to summarize system- fact correlated in a meta-analysis. atic reviews and meta-analyses of psychological research. After an illustration, we introduce these new meta- regression tests for a correlation of standard errors and RE Versus Correlated Heterogeneity heterogeneity. We then apply these new tests to dozens of meta-analyses to evaluate whether there is evidence The RE model assumes that effect sizes, such as Cohen’s of a predominant correlation between standard errors d, di, are normally distributed as: and heterogeneity in psychology. Only after offering evidence supporting these two important lines of reason- = + + = δ θ ε i 1 2 , ,. . . . d k i i i (1) ing do we directly address our main thesis: that UWLS statistically dominates RE in typical application. Random heterogeneity, θi, is assumed to be normally As an illustrative example, consider the once highly distributed with variance, τ2 and independent of the regarded theory of ego depletion. Ego depletion posits sampling errors, εi , and its variance, σi 2. Thus, the RE that people have a limited supply of willpower and it model implies that squared deviations from the mean, decreases with overuse. Ego depletion is one of the ( ) di − δ 2, will be randomly and independently distributed theories that have come into question because of the around σi 2 + τ2 . failure of a PMR.1 Hagger et al.’s (2016) PMR found a Regression analyses of squared deviations have a long scientifically and statistically negligible ego-depletion history as tests of the assumptions of a statistical model. effect (d = 0.04). This PMR is so large that any scientifi- Examples include the White, the Park, and the Glejser cally non-null effect can be rejected with low rates of tests of homoskedasticity (Glejser, 1960; Park, 1966; both Type I and Type II errors (Witte & Zenker, 2017). White, 1980). Tests of individual variances are based on Therefore, all statistically significant ego-depletion find- specific regression models. A systematic pattern among ings (45%) are false positives (Carter et al., 2015). these squared deviations is treated as evidence that the However, conventional meta-analysis misses the assumed model is invalid (heteroskedastic) and its stan- underlying weakness of ego-depletion experiments alto- dard errors biased. We use meta-regression analysis gether. For example, strong evidence of a medium to (MRA) to investigate whether the observed heterogene- large ego-depletion effect, d = 0.62 (confidence interval ity, ( ) di − δ 2, is positively correlated with SEi , the estimate \[CI\] = \[0.57, 0.67\]), was published in Psychological Bul- of σi . Such a correlation, if found, is a violation of the letin (Hagger et al., 2010).2 Later, the RE estimate from RE model and provides evidence that small-sample stud- 116 ego-depletion studies remains of notable size and ies are more heterogeneous. clear statistical significance—d = 0.426 (CI = \[0.339, These considerations lead to a meta-regression of the 0.513\]; Carter et al., 2015). Our new meta-regression square root of the variance ratio (VR) on a study’s SEi methods, see Equation 2 below, finds clear evidence that with a test of whether heterogeneity is correlated with heterogeneity is correlated with the standard errors of SE (H0: γ1 = 0): ego-depletion effects. Thus, for ego depletion, the RE model may not be valid, and its results should be treated 2 2 2 VR d SE SE u = − + + ( ) / ( ) . δ τ γ i i i i i 0 1 γˆ ˆ + = (2) with caution. In this article, we develop new meta-regression meth- For the derivation and statistical rationale of this VR- ods to identify whether heterogeneity is associated with MRA (Equation 2), see Section I of the Supplemental standard errors and thereby with sample size both within Material available online. Next, we report simulations Advances in Methods and Practices in Psychological Science 5(4) 3 that establish the validity of VR-MRA as a test of correlated heterogeneity and thereby a test of the valid- ity of the RE model. In this article, the central role of this new test, VR-MRA, is to establish the widespread correlation of standard errors and heterogeneity by apply- ing VR-MRA to a preregistered meta-meta-analysis (see Meta-research Evidence section below). Simulations We conduct several simulations in which the key research dimensions (heterogeneity, the distribution of sample sizes, and mean effect sizes) are set to reflect the typical values found in large surveys of psychological research (Fraley & Vazire, 2014; Stanley et al., 2019). Supplement II.A in the Supplemental Material provides full details of simulations of VR-MRA using the core of past simulations’ code and design, previously posted on OSF (https://osf .io/eh974/; Stanley, 2019) and employed in studies of psychology (Stanley & Doucouliagos, 2022; Stanley et al., 2021) using other meta-analysis methods. The distribution of sample sizes in the primary studies {15, 35, 50, 100, or 200} mirrors a large survey of person- ality and social-psychology experiments (Fraley & Vazire, 2014). Following Stanley et al. (2021), each simulated meta-analysis has its mean effect (in terms of Cohen’s d) drawn for a beta distribution (1, 3) to match the effect sizes found in surveys of psychology. For further details, see Supplement II.A in the Supplemental Material. Indi- vidual studies comprising a meta-analysis are drawn from a population with the same mean. However, following the RE model, the true effect of each study is a random normal draw from a population with the same mean and a fixed standard deviation, τ, independent of sampling errors. Stanley (2019) and Stanley et al. (2021) set het- erogeneity, τ = {.1, .2, .3, .4, .5d}, to approximate what is seen among the 53 meta-analyses of psychology experi- ments, measured as Cohen’s d, from Stanley et al. (2018). We focused on these 53 meta-analyses because they con- tain a large number of experimental studies (3,541 in total) that are all measured in comparable standardized- mean-difference units. We filed a preanalysis plan to use these same 53 meta-analyses as a test of the RE model and correlated heterogeneity.3 Each of the 10,000 simu- lated meta-analyses has heterogeneity, randomly and uniformly distributed from τ = .1 to .5, independent of sampling errors. In all simulation conditions but one, τ is held constant for all studies in a meta-analysis, forcing heterogeneity to be the same for all studies regardless of their sample size (see Supplement II.A in the Supplemen- tal Material). Table 1 reports the mean, Type I error rate, and power of the estimated VR-MRA slope coefficient, ˆ γ1 . The first column, 1: RE Model Imposed, reports these statistics for ˆ γ1, from Equation 2, when there are 10,000 replications of VR-MRA and when heterogeneity is fixed for all studies in a meta-analysis regardless of their sample size or stan- dard errors. Following past simulation studies and to encompass the typical number of effects per meta-analysis, we assumed that each meta-analysis contained either k = 20 or 80 studies. However, out of an abundance of caution, we also simulate k = 10, 30, and 160 to cover the large majority of meta-analyses in psychology.4 Note that ˆ γ1 has a small positive bias (≈.103) when heterogeneity is, in fact, independent of standard errors. As discussed in Section II of the Supplemental Material, this positive average is caused by the term of di 2 in stan- dard errors’ formula, which, in turn, is correlated with the numerator of VR. In Column 2, Root n: RE Model Imposed, we replace the independent variable, SEi , with the square root of the study’s sample size, ni , which we know to be independent of di 2. As a result, this bias vanishes to inconsequential rounding errors, and its Type I errors are always well within their .05 nominal level. For our purposes, maintaining Type I errors within their nominal 5% level is our central concern, and the VR-MRAs with SEi achieve this (see Column 1 of Table 1). We use standard errors because in practice, we do not always know the corresponding samples sizes. In general, standard errors are routinely reported in meta- analyses, whereas sample sizes may not be. Nonetheless, VR-MRA has an important limitation when applied to individual meta-analyses—low statisti- cal power. Column 3: Correlated Heterogeneity reports the results of the same simulation experiment but where heterogeneity is forced to be moderately correlated with standard errors. In particular, τ is set at {.4, .3, .3, .3, .15 d} for sample sizes {15, 35, 50, 100, 200}, respectively. To be clear, small- and large-sample studies can have very different true effects relative to other small- and large- sample studies as dictated by random draws from a fixed normal distribution. However, studies with the largest sample size will tend to have less heterogeneity than those with the smallest sample sizes, whereas the other 60% have the same heterogeneity variance found to be typical in psychology. With this moderately correlated heterogeneity, the average estimates of γ1 increases by nearly 10-fold; see Column 3 of Table 1. However, the probability of detecting this correlated heterogeneity is only about 32% for a meta-analysis of 80 studies and about 59% when there are 160 studies. For the median number of studies in psychology meta-analyses (k = 31), power is quite low (about 14%). As staunch advocates of the importance of adequate statistical power, we can- not ignore the low power of VR-MRA (Ioannidis et al., 2017; Stanley et al., 2018, 2022). Thus, VR-MRA should not be applied to the average meta-analysis alone, but only to large meta-analyses or 4 Stanley et al. Table 1. VR-MRA Simulations: 10,000 Replications N studies 1: RE model imposed 2: Root n: RE model imposed 3: Correlated heterogeneity 4: Publication bias k M Type I M Type I M Power M Power 10 .0824 .0348 .0006 .0335 .9122 .0573 1.123 .0625 20 .0887 .0418 .0013 .0371 1.047 .1063 1.096 .1325 30 .1029 .0431 .0013 .0369 1.080 .1395 1.110 .1662 80 .1196 .0495 .0016 .0379 1.153 .3239 1.163 .4247 160 .1236 .0530 .0016 .0326 1.170 .5896 1.150 .6310 Average .1034 .0444 .0013 .0356 1.0724 .2433 1.128 .2834 Note: M is the average value of the VR-MRA slope coefficient across 10,000 simulations. Type I is the Type I errors of rejecting a zero VR-MRA slope when heterogeneity is independent of standard errors and the RE model is valid. RE model imposed forces the RE model to be valid. Root n uses the square root of a study’s per-group sample size as the independent variable. Correlated heterogeneity assumes that τ is correlated with standard errors. The publication-bias condition also imposes the RE model on the simulations; however, half of the reported studies are selected to be statistically positive. VR-MRA = variance ratio meta-regression analysis; RE = random effects. across many meta-analyses. Nevertheless, knowing that a test has low power and interpreting the findings, accordingly, may still allow using the test more broadly. There is precedence for this practice in tests that probe selective-publication bias. For example, the Egger test has comparable power, and it is frequently used (Egger et al., 1997; Stanley et al., 2021). However, results of the Egger test do not permit conclusive statements (Lau et al., 2006). We caution inappropriate overinterpretation of the VR-MRA test if applied to single meta-analyses. Illustration Returning to Carter et al.’s (2015) ego-depletion meta- analysis, VR-MRA provides clear evidence that heteroge- neity is correlated with standard errors, ˆ γ1 = 1.90 (CI = \[0.67, 3.13\]; p \< .01), and thereby the RE summary of ego-depletion meta-analysis should be treated with some reservation.5 Recall, VR-MRA tends to have low power; thus, it is all the more remarkable that we found clear statistical evidence that small ego-depletion studies are more heterogeneous. In Section IV of the Supplemental Material, we discuss in detail exactly how UWLS, weighted average of the adequately powered (WAAP), and VR-MRA are calculated for ego depletion using both STATA and R. The practical implication of this example is to not trust RE and instead use alternate methods that are not based on the RE model. The UWLS is such a meta- analysis summary estimator. It is neither fixed effect (FE) nor RE. UWLS and FE always give the same point estimate, but UWLS automatically accommodates hetero- geneity when present. Like RE and FE, UWLS is an inverse variance weighted average. However, RE’s inverse variance weights are 1 2 2 , whereas UWLS SEi +ˆ τ 1 weights = for γ \> 0. The parameter, γ, accommodates heterogeneity but is missing in FE (Stanley & Doucouliagos, 2015, 2017). That is, instead of assuming that heterogeneity is additive and indepen- dent of the sampling-error variance, SEi 2, UWLS allows the heterogeneity variance to vary proportionately with SEi 2 . Thus, UWLS offers a model in which heterogeneity is correlated with standard error. When small-study find- ings are more heterogeneous, hence unreliable, UWLS fittingly down-weights them relative to RE: 1 versus γSEi 2 1 SEi +ˆ 2 2 τ. For a more detailed discussion of UWLS, see UWLS section below. For ego depletion, UWLS = 0.347 (CI = \[0.263, 0.431\])—see Section IV in the Supplemental Material. Because UWLS accommodates correlated het- erogeneity, UWLS estimates mean effect to be notably smaller than RE. The WAAP is a version of UWLS that down-weights small studies even further. Not only are small ego- depletion studies inadequately powered, VR-MRA offers evidence that they are more unreliable as well. Only one ego-depletion study is adequately powered (power \> 80%), and only 10 of 116 have power greater than 50%, retrospectively calculated.6 WAAP uses Cohen’s (1988) widely accepted convention of 80% to define adequate power (Stanley et al., 2017). WAAP = UWLS when UWLS is calculated only on those studies with retrospective power greater than 80%.7 For ego depletion, WAAP = 0.100 (CI = \[–0.096, 0.295\]). Likewise, UWLS calculated on only those ego-depletion studies with at least 50% power is not statistically significant, d = 0.193 (CI = \[–0.048, 0.435\]). When RE is dominated by studies with retrospective power less than 50%, such as ego-depletion research, Stanley et al. (2022) showed that RE findings are not likely to be credible. To properly reflect both the low power and the unreliability (i.e., high heterogeneity) γSEi 2 Advances in Methods and Practices in Psychological Science 5(4) 5 of small studies, this illustration demonstrates how cor- related heterogeneity makes it imperative to down-weight small studies much more than RE. In the UWLS section below, we report the statistical properties of RE, UWLS, and WAAP when there is correlated heterogeneity. First, however, we demonstrate how correlated heterogeneity is widespread in psychological research. Meta-research Evidence To overcome VR-MRA’s low power in individual meta- analyses, we conducted a meta-analysis of many VR-MRA results. Meta-analysis is often regarded as the best way to increase the statistical power of individual studies and to resolve the ambiguity of mixed findings across stud- ies. Jackson and Turner (2017) showed that five or more studies “reasonably consistently achieve powers from random-effects meta-analyses that are greater than the studies that contribute to them” (p. 280). To increase the power of individual VR-MRA results, we combined the VR-MRA findings from these 53 “preregistered” meta- analyses and used RE meta-analysis to summarize their aggregate evidence. Our purpose for seeking meta- research evidence of the correlation of standard errors and heterogeneity is to establish that this correlation is widespread among meta-analyses and to gauge its mag- nitude to accurately calibrate simulations that compare the statistical properties of RE and UWLS—see UWLS section below. Consistent with our simulations and correlated het- erogeneity (Column 3 of Table 1), we found that 18 (or 34%) of these VR-MRAs have a statistically positive esti- mate of γ1. Across these 53 VR-MRAs, the RE estimate of γ1 is 1.46 (z = 2.53; p ≈ .01; CI = \[0.33, 2.59\]). Closer inspection of these 53 meta-analyses uncovers that the two meta-analyses that provide the strongest evidence against RE (i.e., largest ˆ γ1 ) likely contain coding errors because some \|dis\| \> 10. To be sure that our evidence is not contaminated by a few outliers, we removed the upper and lower 5% of these γ1 estimates. Across the remaining 47 meta-analyses, the RE estimate of γ1 is notably smaller (1.06) yet has a clearer statistical signal (z = 5.52; p \< .001; CI = \[0.68, 1.44\]). To further ensure that this meta-research evidence of correlated heteroge- neity is not somehow spurious, we conducted another set of simulation experiments, this time of RE meta-meta- analyses of VR-MRA estimates below. For further details, see Supplement II.B in the Supplemental Material. and calculates a conventional RE estimate of these 50 meta-regression estimates of γ1. Just as the previous simulations of VR-MRA, random subject data are first generated; each study’s effect size and standard errors are calculated, forming meta-analyses of different sizes; and γ1 and its standard errors are estimated for each meta-analysis. These meta-meta-analysis simulations dif- fer by further collecting 10,000 random groups of 50 VR-MRA results and calculating 10,000 RE meta- VR-MRAs. As a result, each simulation entails 4 billion random subjects, 500,000 VR-MRAs, and 10,000 RE meta-VR-MRAs, each one of which imitates the typical conditions found among these same 53 experimental meta-analyses. Column 1 of Table 2 reports the average RE estimate and z value across 10,000 replications of 50 VR-MRAs in which heterogeneity is independent of sampling error and its variance is forced to be the same for all studies in a meta-analysis. Table 2 also reports the largest and smallest values for any of the RE estimates (and their z values) of 50 VR-MRAs found among 10,000 replications. In this way, we can better evaluate whether our meta- research findings for a particular RE estimate of VR-MRAs are merely chance or genuine evidence of correlated heterogeneity. Not a single RE estimate of γ1 from 50 VR-MRAs in 10,000 replications is nearly as large as what we found (1.06). Likewise, the z value for RE in our meta-research (5.52) is larger than the largest z value in 10,000 replications when heterogeneity is independent of standard errors—see Column 1, Table 2. In contrast, when these simulations assume that small studies have higher heterogeneity than large studies, the results that we found for either 53 or 47 Psychological Bulletin meta- analysis is quite consistent with what is seen in these meta-VR-MRA simulations—see Column 2, Table 2. Thus, we have clear meta-research evidence of correlated het- erogeneity in psychology. Meta-meta-analysis simulations To the same simulation design and structure used for VR-MRA estimates and reported in Table 1, we added a loop that collects 50 random VR-MRA findings at a time Robustness of the meta-research evidence For the sake of robustness and further independent vali- dation, we investigate a second set of meta-analyses. Kvarven et al. (2020) conducted a systematic review of all meta-analyses that have an associated PMR and found 15 such pairs. The RE estimate of only 15 VR-MRA esti- mates will have much less power. Nonetheless, the RE estimate of γ1 from these 15 VR-MRA estimates is 1.24 (z = 3.96; p \< .001; CI = \[0.63, 1.86\]). Again, we corrobo- rated the validity of this meta-research evidence by con- ducting yet another simulation experiment in which the RE model is imposed. This RE estimate, 1.24, is larger than any of the 10,000 replications, each with 16 VR-MRA esti- mates of γ1, when the RE is true. As before, these meta- research findings are quite consistent with what is seen 6 Stanley et al. kk Statistics 1: RE model imposed 2: Correlated heterogeneity RE estimate z RE estimate z 50 M 0.1139 0.8685 1.106 7.743 50 SD 0.1290 0.9918 0.1405 1.147 50 Minimum –0.3592 –3.011 0.4878 3.138 50 Maximum 0.6076 4.406 1.610 11.88 16 M 0.1595 0.6617 1.104 4.306 16 SD 0.2316 0.9837 0.2523 1.078 16 Minimum –0.7015 –3.293 0.2121 0.6680 16 Maximum 1.065 4.530 2.098 8.680 Table 2. Simulations of 10,000 Random-Effects Meta-Analyses of VR-MRAs Note: kk is the number of VR-MRA meta-regression analyses summarized by each RE meta-analysis. z is the RE z value. RE model imposed forces the RE model to be valid. Correlated heterogeneity reports simulations in which τ is correlated with standard errors. VR-MRA = variance ratio meta-regression analysis; RE = random effects. among the simulations of correlated heterogeneity—see Table 2, bottom half. Finally, as another robustness check, we provide fur- ther meta-research evidence that heterogeneity is cor- related with standard errors from an alternate MRA model of RE variances in Section III of the Supplemental Material: 2 TV d SE = − = + + 2 νˆ ( ) . δ β β 0 1 i i i i (3) See Section III of the Supplemental Material for a discussion of the total variance meta-regression analysis (TV-MRA) model (Equation 3), its application to these sets of meta-analyses as reported above, and the corre- sponding simulation findings of 10,000 RE meta-analyses of collections of both 50 and 16 randomly generated meta-regressions of this alternative model of RE’s vari- ance. Evidence from TV-MRA model (Equation 3) sup- ports the above evidence of a correlation between heterogeneity and SE in psychology—see the Section III in the Supplemental Material. Discussion Combining evidence across meta-regression tests con- sistently supports the hypothesis that heterogeneity is correlated with standard errors, thereby inconsistent with the RE model. This correlation is also corroborated in the aggregate by a correlation between the median standard error and RE estimated heterogeneity, ˆ τ 2, across 200 Psychological Bulletin meta-analyses (r = .2; p \< .01; Stanley et al., 2018). But why would small studies be found to be more heterogeneous? There are several likely and overlapping reasons. Researcher flexibility in choosing methods, protocols, and outcome measures provides the variation across which a statistically significant result can be selected. Such researcher flexibility generates heteroge- neity, clearly seen in large differences of heterogeneity found among tightly controlled multilab replications versus meta-analyses (Klein et al., 2018; Kvarven et al., 2020; Linden & Hönekopp, 2021). As seen in many simu- lations, small studies require more intensive selection across this heterogeneity to achieve statistical signifi- cance (Stanley & Doucouliagos, 2014). When 50% of the reported results have been selected to be statistically significant, the average value of VR-MRA’s slope coef- ficients, ˆ γ1, is quite consistent with simulation results when correlated heterogeneity is imposed—see Column 4 of Table 1. In 100,000 replications of this simulation design in which the RE model is imposed on individual studies and there is 50% selection for statistical signifi- cance, we found that the smallest quintile of studies reported results with twice the heterogeneity (average ˆ 2 τ = 0.1465) as the largest quintile (average ˆ 2 τ = 0.0733). This factor of 2 is also seen among meta-analyses of health and medicine (IntHout et al., 2015). Thus, we know that researcher flexibility combined with selection for statisti- cal significance can be a cause of higher heterogeneity in small studies. However, other forces are also likely to be at work. By their very nature, exploratory studies are likely to find notably different effect sizes from one exploration to the next. Small studies may employ lower-quality standards with higher risk of bias (IntHout et al., 2015, p. 866), and less reliability generates higher heterogene- ity. Correlated heterogeneity may be caused by a mixture of different types of “replications” that typically comprise meta-analyses. Several researchers have classified repli- cations as “conceptual” versus “direct” (or “close”; Advances in Methods and Practices in Psychological Science 5(4) 7 Hedges & Schauer, 2019; Linden & Hönekopp, 2021; Schauer & Hedges, 2020; S. Schmidt, 2009). Direct or close replications involve the use of the same experi- mental procedures in an effort “to replicate an earlier study as faithfully as possible” (Linden & Hönekopp, 2021, p. 360). In contrast, studies that are regarded as conceptual replications use different methods to explore the boundaries of theory, widen the field’s understand- ing, and assist in developing new theory (S. Schmidt, 2009). Thus, the results from conceptual replications are expected to produce higher heterogeneity than direct replications (Linden & Hönekopp, 2021). Furthermore, direct replications often use large sam- ple sizes (e.g., the Open Science Collaboration and Many Labs projects) to ensure adequate power. When not adequately powered, a lack of replication success would be quickly dismissed as the expected result of low power rather than attributed to the original experiment. Con- versely, conceptual replications, which are more numer- ous, face no such demands, as demonstrated by the low power that many surveys of psychology have found (Cohen, 1962; Fraley & Vazire, 2014; Maxwell, 2004; F. L. Schmidt & Oh, 2016; Stanley et al., 2018). In fact, small samples might be advantageous for conceptual replications: A safer strategy might be to “salami-slice” one’s resources to generate more studies which, with suf- ficient analytical flexibility, will almost certainly pro- duce a number of publishable studies. . . . Authors may therefore (consciously or unconsciously) con- duct a larger number of smaller studies, . . . rather than risk investing their limited resources in a smaller number of larger studies. (Vankov et al., 2014, pp. 1–2) Thus, meta-analyses that include largely conceptual replications along with a few direct replications would be expected to produce higher heterogeneity in small studies than in large ones. Needless to say, VR-MRA has limitations beyond the low power in single meta-analyses discussed above. Low power will be exacerbated in fields that have few studies per meta-analysis, as seen in some fields of medicine and health psychology. VR-MRA, as a regression, requires notable variation of its independent variable (standard errors or sample sizes) in a meta-analysis to be estimated reliably. Nevertheless, combining many VR-MRAs can be informative if most have notable variation in sample sizes. scientific contribution. “Studies with low statistical power produce inherently ambiguous results because they often fail to replicate” (Psychonomic Society, 2012, p. 1). “You should routinely provide evidence that your study has sufficient power to detect effects of substantial inter- est (e.g. see Cohen, 1988)” (American Psychological Association \[APA\], 2010, p. 30). Yet the majority of stud- ies in psychology are underpowered (Stanley et al., 2018). For decades, many psychologists have recognized that small studies are of little scientific value (APA, 2010; Cohen, 1962, 1988; Fraley & Vazire, 2014; Maxwell, 2004; Psychonomic Society, 2012; Rossi, 1990), and areas of research dominated by small studies (power \< 50%) are associated with highly biased and falsely positive RE findings (Stanley et al., 2022): Unless psychologists begin to incorporate methods for increasing the power of their studies, the pub- lished literature is likely to contain a mixture of apparent results buzzing with confusion. . . . Not only do underpowered studies lead to a confusing literature but they also create a literature that con- tains biased estimates of effect sizes. (Maxwell, 2004, p. 161) When small studies systematically produce highly het- erogeneous findings, their scientific contribution further erodes. Recent surveys of psychology meta-analyses found substantial heterogeneity among study findings, average τ \> 0.3 d—(Linden & Hönekopp, 2021, p. 7; Stanley et al., 2018).8 When small studies have yet higher heterogeneity than average, small to medium results will be overwhelmed by uncertainty. Thus, the results from small-sample studies should be routinely treated with skepticism. Heterogeneity correlated with standard errors also has implications for the practice of systematic reviews and meta-analysis. It has long been known that RE over- weight small studies and thereby is highly biased when there is publication selection bias (Carter et al., 2018; Henmi & Copas, 2010; Poole & Greenland, 1999; Stanley & Doucouliagos, 2014, 2015). When heterogeneity is correlated with standard errors, the RE model is invalid, and RE will further overweight unreliable small-study findings. Fortunately, there is a simple alternative meta- analysis approach, the UWLS, that automatically accom- modates correlated heterogeneity and gives unreliable and potentially biased small studies less weight. Implications for Practice Since Cohen (1988), statistical power has been univer- sally acknowledged as a central determinant of a study’s Unrestricted Weighted Least Squares As discussed above, UWLS is a simple weighted average that allows heterogeneity to be correlated with standard errors. UWLS and FE have identical point estimates, but 8 Stanley et al. UWLS standard errors and CIs are larger when there is heterogeneity (Stanley & Doucouliagos, 2015, 2022). UWLS is easily calculated by a simple regression of the standardized effect size (d SE i i / ) on its precision (1/SEi) when there is no intercept: t d SE SE u k i i i i i = = ( ) + = / / , , . . . , . α 1 i 1 2 (4) UWLS is the estimated slope, ˆ α. All regression soft- ware will automatically calculate UWLS, its standard errors, test statistics, and CIs after properly adjusting for heterogeneity.9 Stanley et al. (2017) offered a variation of UWLS that uses only those studies with 80% or higher power, thereby giving the smallest studies no weight at all. Simulations show that this WAAP is less biased than other weighted averages (specifically, RE, FE, and UWLS) when there is publication-selection bias, and the bias reduction can be quite large in application (Ioannidis et al., 2017; Stanley et al., 2017). However, when the RE model is imposed on the simu- lation structure and there is no publication bias, these simulations show that RE has slightly lower mean squared error (MSE) than UWLS (Bom & Rachinger, 2019; Stanley & Doucouliagos, 2014; Stanley et al., 2017). When there is publication-selection bias, these same simulations show that UWLS has notably smaller MSE than RE. What remains to be investigated is whether UWLS will domi- nate RE in all cases when heterogeneity is correlated with standard errors, as typically seen in psychology. Next, we present a new simulation study that considers the consequences of correlated heterogeneity on the statisti- cal properties of RE, UWLS, and WAAP. Simulations Our final simulation study closely followed the simula- tion design of VR-MRA, reported above and detailed in Section II of the Supplemental Material. The code for the core of the design was posted online in 2019 and used in other studies (Stanley, 2019; Stanley & Doucouliagos, 2022; Stanley et al., 2021). The most influential research dimensions are calibrated from large surveys of psycho- logical research (Fraley & Vazire, 2014; Stanley et al., 2018)—for greater details, see Section II of the Supple- mental Material. The central difference of these simulations from those previously published is that we assume that heterogene- ity, τ, is correlated with standard errors to the same degree as seen in our meta-meta-analysis results. In par- ticular, heterogeneity, τ = {.4, .3, .3, .3, .15}, is assumed to be associated with sample sizes, ni = {15, 35, 50, 100, or 200}, respectively, per group. This choice of the dis- tribution of heterogeneity across samples sizes was selected because it produces an average VR-MRA coefficient, ˆ γ1 , quite close to what is seen in our meta-meta-analysis of psychological experiments and their simulations (e.g., Column 2, Table 2). Otherwise, the RE model is forced on these simulations. Specifically, random heterogeneity, θi , and random sampling error, εi , are generated normally, independently, and additively as the RE model demands—recall Equation 1. However, because these simulations force heterogeneity’s standard deviation, τ, to be correlated with standard errors, the data-generating process is somewhere between the RE and UWLS models. In the upper half of Table 3, we report the bias, MSE, and Type I error rate (or power) for RE, UWLS, and WAAP when there is no publication bias; the lower half includes the same information after an assumption that 50% of the reported results have gone through a process of selection for statistical significance. As Table 3 shows, UWLS has smaller MSE and Type I errors than RE in all cases in which heterogeneity is correlated with standard errors and in which there is no publication-selection bias. Biases are inconsequential rounding errors. When there is publication-selection bias (Table 3, bottom half), UWLS improvement over RE is much greater. With 50% publication-selection bias, UWLS’s MSE is only 59% as large as RE, and bias is 73% of RE bias (Table 3, bottom row), and WAAP is better still. Discussion When the heterogeneity variance is correlated with sam- pling error variance (or sample size), simulations show that UWLS dominates RE, and WAAP does even more to reduce bias and MSE when there is publication-selection bias. Because we find robust meta-research evidence that heterogeneity and standard errors are typically correlated in psychology, UWLS (and, whenever possible, preferably its WAAP variant) should be adopted as the conventional meta-analysis estimate of mean effects and summary of systematic reviews. Even if heterogeneity and standard errors are independent and the RE model is entirely valid, simulations show that there is practically nothing to gain by using RE over UWLS when there is no publication- selection bias; however, there is much to lose if there is publication-selection bias (Bom & Rachinger, 2019; Stan- ley & Doucouliagos, 2014; Stanley et al., 2017). When correlated heterogeneity is common, the choice is clear— UWLS. If the systematic reviewer fears the effect of pub- lication-selection bias and wishes to reduce it more aggressively, then there are versions of UWLS that also accomplish this goal—WAAP and weighted and iterative least squares (WILS). WILS uses UWLS to identify whether there is an excess of statistical significance in an area of research and discards those studies most responsible (Stanley & Doucouliagos, 2022; Stanley et al., 2021). Often, the remaining exaggeration is scientifically and Advances in Methods and Practices in Psychological Science 5(4) 9 Table 3. Correlated Heterogeneity: Statistical Properties of RE, UWLS, and WAAP Bias MSE Type I error/power δ k RE UWLS WAAP RE UWLS WAAP RE UWLS WAAP No selection for statistical significance Type I error/power 0 10 0.0006 –0.0014 –0.0013 0.01058 0.00947 0.00949 0.1060 0.0630 0.0600 0 20 –0.0020 –0.0016 –0.0016 0.00560 0.00476 0.00476 0.0800 0.0620 0.0620 0 40 0.0026 0.0023 0.0023 0.00251 0.00208 0.00208 0.0770 0.0540 0.0540 0 80 0.0007 0.0003 0.0003 0.00136 0.00112 0.00112 0.0800 0.0630 0.0630 0 160 0.0008 0.0008 0.0008 0.00063 0.00053 0.00053 0.0580 0.0570 0.0570 Average 0.0005 0.0001 0.0001 0.00414 0.00359 0.00360 0.0802 0.0598 0.0592 β 10 –0.0003 –0.0022 –0.0028 0.01076 0.00917 0.01085 0.5875 0.5447 0.3812 β 20 –0.0009 –0.0031 –0.0040 0.00527 0.00454 0.00550 0.6731 0.6662 0.6207 β 40 –0.0013 –0.0036 –0.0048 0.00265 0.00225 0.00277 0.7526 0.7620 0.7601 β 80 –0.0016 –0.0037 –0.0052 0.00135 0.00116 0.00154 0.8241 0.8307 0.8294 β 160 –0.0017 –0.0040 –0.0055 0.00067 0.00060 0.00088 0.8687 0.8745 0.8739 Average –0.0012 –0.0033 –0.0045 0.00414 0.00354 0.00431 0.7412 0.7356 0.6931 50% selection for statistical significance Type I error/power 0 10 0.2618 0.2092 0.1967 0.07455 0.04924 0.04305 0.7014 0.4080 0.2749 0 20 0.2626 0.2087 0.2019 0.07201 0.04627 0.04297 0.9571 0.7951 0.7486 0 40 0.2633 0.2086 0.2060 0.07093 0.04489 0.04372 0.9999 0.9907 0.9855 0 80 0.2637 0.2086 0.2084 0.07027 0.04421 0.04410 1.000 1.000 1.000 0 160 0.2639 0.2088 0.2087 0.07002 0.04393 0.04391 1.000 1.000 1.000 Average 0.2630 0.2088 0.2043 0.07156 0.04571 0.04355 0.9317 0.8388 0.8018 β 10 0.1672 0.1236 0.0928 0.03874 0.02458 0.01997 0.9336 0.8177 0.5069 β 20 0.1693 0.1240 0.0917 0.03589 0.02150 0.01611 0.9943 0.9687 0.8410 β 40 0.1711 0.1252 0.0917 0.03474 0.02019 0.01466 10.000 0.9997 0.9861 β 80 0.1722 0.1258 0.0921 0.03437 0.01963 0.01391 1.000 1.0000 0.9956 β 160 0.1711 0.1245 0.0905 0.03348 0.01885 0.01322 1.000 1.0000 0.9978 Average 0.1702 0.1246 0.0918 0.03544 0.02095 0.01557 0.9856 0.9572 0.8655 Note: Mean effect δ = 0 measured as Cohen’s d. δ = β means that the true mean effect is generated from a β (1, 3) distribution that has median d = 0.206 and is highly skewed. k is the number of estimates. RE and UWLS denote the RE and UWLS meta-analysis averages, respectively. MSE = mean squared error; RE = random effects; UWLS = unrestricted weighted least square; WAAP = weighted average of the adequately powered (Stanley et al., 2017). practically insignificant (Stanley & Doucouliagos, 2022). When all studies in a meta-analysis are small, then any meta-analytic estimate should be interpreted with great caution (Ioannidis, 2005; Stanley et al., 2022). Conclusion We introduce new meta-regression methods, VR-MRA and TV-MRA, that can identify whether the magnitude of heterogeneity across study findings is correlated with their standard errors. Evidence from the meta-analysis of 53 “preregistered” meta-analyses (as well as a separate set of 15 meta-analyses) finds clear and robust evidence of this correlation and that small-sample studies typically have higher heterogeneity. Such variable heterogeneity is a violation of the RE model of additive and indepen- dent heterogeneity—recall Equation 1. Both findings have important implications for practice. For decades, there has been wide recognition that the low power (and small sample size) of the typical psychol- ogy study compromises reliable scientific inference (APA, 2010; Cohen, 1962, 1988; Maxwell, 2004; Psychonomic Society, 2012; Rossi, 1990). When small studies have not only inadequate statistical power but also high heteroge- neity, their scientific contribution is dubious. Our results, therefore, further expose the necessity of preregistration and preanalysis plans if typical sample sizes (n ≤ 50, per group) are to be used at all (Fraley & Vazire, 2014). The meta-research evidence presented in this article also serves as a test of the RE model. When the hetero- geneity variance is correlated with the sampling-error variance to the degree found among in dozens of VR- MRAs, simulations show that RE is dominated by an alternative weighted average, the UWLS. With or without publication-selection bias, UWLS statistically dominates RE when heterogeneity is correlated. The advantage of 10 Stanley et al. UWLS over RE is quite notable when there is selection for statistical significance (i.e., publication-selection bias or questionable research practices). UWLS is built on a model of multiplicative heterogeneity and thereby easily accommodates correlated heterogeneity. It has long been known that UWLS dominates RE when there is publica- tion bias. When the magnitude of heterogeneity is also correlated with standard errors, the UWLS advantage is absolute. Thus, there is a strong case for the UWLS weighted average with its WAAP and WILS variants to replace random effects as the conventional meta-analysis estimator of psychological research. report the findings from MRA model (Equation 3) for these same “preregistered” meta-analyses. 4. The median number of estimates per meta-analysis is 31, M = 60, and 92% have fewer than 160 studies (Stanley et al., 2018). 5. For the sake of caution, we used heteroskedastic-robust stan- dard errors. 6. WAAP and these power calculations use UWLS as the estimate of the mean effect and each study’s reported standard errors to calculate retrospective power (Stanley et al., 2017, 2022). 7. The STATA and R codes for WAAP are given in Section IV of the Supplemental Material. 8. In addition, the average τ is 0.333 among the 53 meta-analyses used above, and it is 0.305 among Kvarven et al.’s (2020) 15 meta-analyses. When heterogeneity is this large, successful repli- cation is unlikely (Stanley et al., 2018). 9. In R, the code is uwls \<- lm(t \~ precision -1, data = dat) for t = the standardized effect size, precision = 1/SE, and the data set defined as dat. In STATA, the command is regress t preci- sion, noconstant. Transparency Action Editor: Pamela Davis-Kean Editor: David A. Sbarra Author Contribution(s) T. D. Stanley: Conceptualization; Data curation; Formal analysis; Investigation; Methodology; Software; Validation; Writing – original draft; Writing – review & editing. Hristos Doucouliagos: Conceptualization; Writing – review & editing. John P. A. Ioannidis: Conceptualization; Writing – review & editing. Declaration of Conflicting Interests The author(s) declare that there were no conflicts of interest with respect to the authorship or the publication of this article. Open Practices Open Data: https://osf.io/pjkby Open Materials: https://osf.io/pjkby Preregistration: https://osf.io/wdg5y All data and materials have been made publicly available via OSF and can be accessed at https://osf.io/pjkby. The analysis plan was preregistered at OSF and can be accessed at https://osf.io/wdg5y. This article has received badges for Open Data, Open Materials, and Preregistration. More infor- mation about the Open Practices badges can be found at http://www.psychologicalscience.org/publications/badges. ORCID iD T. D. Stanley https://orcid.org/0000-0002-3205-1983 Notes 1. Before this replication, Carter et al. (2015) found clear evi- dence of publication-selection bias among the ego-depletion experiments and concluded that “meta-analytic evidence does not support the proposition (and popular belief) that self-control functions as if it relies on a limited resource” (p. 812). 2. All confidence intervals reported in this paper are 95%. 3. This preanalysis plan was posted at https://osf.io/scgqe/ on December 24, 2021, before the VR-MRA model was conceived. At the time, we had developed a different family of MRA models, see Equation 3. In Section III of the Supplemental Material, we References American Psychological Association. (2010). Manual of the American Psychological Association (6th ed.). Bom, P. R. D., & Rachinger, H. (2019). A kinked meta-regres- sion model for publication bias correction. Research Synthesis Methods, 10, 497–514. Carter, E. C., Kofler, L. E., Forster, D. F., & McCullough, M. E. (2015). A series of meta-analytic tests of the depletion effect: Self-control does not seem to rely on a limited resource. Journal of Experimental Psychology: General, 144, 796–815. Carter, E. C., Schönbrodt, F. D., Gervais, W. M., & Hilgard, J. (2018). Correcting for bias in psychology: A comparison of meta-analytic methods. Advances in Methods and Practices for Psychological Science, 2, 115–144. Cohen, J. (1962). The statistical power of abnormal-social psy- chological research: A review. The Journal of Abnormal and Social Psychology, 65, 145–153. Cohen, J. (1988). Statistical power analysis in the behavioral sciences (2nd ed.). Academic Press. Egger, M., Smith, G. D., Schneider, M., & Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. BMJ, 315, 629–634. Fraley, R. C., & Vazire, S. (2014). The n-pact factor: Evaluating the quality of empirical journals with respect to sample size and statistical power. PLOS ONE, 9, Article e109019. https://doi.org/10.1371/journal.pone.0109019 Glejser, H. (1960). A new test for heteroscedasticity. Journal of the American Statistical Society, 64, 316–323. Hagger, M. S., Chatzisarantis, N. L. D., Alberts, H., Anggono, C. O., Birt, A., Brand, R., & Cannon, T. (2016). A multi- lab preregistered replication of the ego-depletion effect. Perspectives on Psychological Science, 11, 546–573. Hagger, M. S., Wood, C., Stiff, C., & Chatzisarantis, N. L. D. (2010). Ego depletion and the strength model of self-con- trol: A meta-analysis. Psychological Bulletin, 136, 495–525. Hedges, L. V., & Schauer, J. M. (2019). Statistical analyses for studying replication: Meta-analytic perspectives. Psychological Methods, 24(5), 557–570. Advances in Methods and Practices in Psychological Science 5(4) 11 Henmi, M., & Copas, J. B. (2010). Confidence intervals for random effects meta-analysis and robustness to publication bias. Statistics in Medicine, 29, 2969–2983. IntHout, J., Ioannidis, J. P. A., Borm, G. F., & Goeman, J. J. (2015). Small studies are more heterogeneous than large ones: A meta-meta-analysis. Journal of Clinical Epidemiology, 68, 860–869. Ioannidis, J. P. A. (2005). Why most published research find- ings are false. PLOS Medicine, 2, Article e124. https://doi .org/10.1371/journal.pmed.0020124 Ioannidis, J. P. A. (2016). The mass production of redundant, misleading, and conflicted systematic reviews and meta- analyses. The Milbank Quarterly, 94, 485–514. Ioannidis, J. P. A., Stanley, T. D., & Doucouliagos, H. C. (2017). The power of bias in economics research. The Economic Journal, 127, F236–F265. Jackson, D., & Turner, R. (2017). Power analysis for random- effects meta-analysis. Research Synthesis Methods, 8, 290–302. Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., Aveyard, M., Axt, J. R., Babalola, M. T., Bahník, Š., Batra, R., Berkics, M., Bernstein, M. J., Berry, D. R., Bialobrzeska, O., Binan, E. D., Bocian, K., Brandt, M. J., Busching, R., . . . Nosek, B. A. (2018). Many Labs 2: Investigating variation in replicability across sample and setting. Advances in Methods and Practices in Psychological Science, 1(4), 443–490. https://doi.org/ 10.1177/2515245918810225 Kvarven, A., Strømland, E., & Johannesson, M. (2020). Comparing meta-analyses and preregistered multiple-laboratory replication projects. Nature: Human Behavior, 4, 659–663. Lau, J., Ioannidis, J. P. A., Terrin, N., Schmid, C. H., & Olkin, I. (2006). The case of the misleading funnel plot. BMJ, 333(7568), 597–600. Linden, A. H., & Hönekopp, J. (2021). Heterogeneity of research results: A new perspective from which to assess and pro- mote progress in psychological science. Perspectives on Psychological Science, 16(2), 358–376. Maxwell, S. E. (2004). The persistence of underpowered stud- ies in psychological research: Causes, consequences, and remedies. Psychological Methods, 9, 147–163. Open Science Collaboration. (2015). Estimating the repro- ducibility of psychological science. Science, 349(6251), aac4716. https://doi.org/10.1126/science.aac4716 Owens, D. K., Lohr, K. N., Atkins, D., Treadwell, J. R., Reston, J. T., Bass, E. B., Chang, S., & Helfand, M. (2010). AHRQ Series Paper 5: Grading the strength of a body of evidence when comparing medical interventions—Agency for Healthcare Research and Quality and the Effective Health-Care Program. Journal of Clinical Epidemiology, 63(5), 513–523. Park, R. E. (1966). Estimation with heteroscedastic error terms. Econometrica, 34, 888. Poole, C., & Greenland, S. (1999). Random-effects meta- analyses are not always conservative. American Journal of Epidemiology, 150, 469–475. https://doi.org/10.1016/ j.jclinepi.2009.03.009 Psychonomic Society. (2012). New statistical guidelines for journals of the psychonomic society. https://www.springer .com/psychology?SGWID=0-10126-6-1390050-0 Rossi, J. S. (1990). Statistical power of psychological research: What have we gained in 20 years? Journal of Consulting and Clinical Psychology, 58, 646–656. Schauer, J. M., & Hedges, L. V. (2020). Assessing heterogeneity and power in replications of psychological experiments. Psychological Bulletin, 146, 701–719. Schmidt, F. L., & Oh, I.-S. (2016). The crisis of confidence in research findings in psychology: Is lack of replication the real problem? Or is it something else? Archives of Scientific Psychology, 4(1), 32–37. Schmidt, S. (2009). Shall we really do it again? The powerful concept of replication is neglected in the social sciences. Review of General Psychology, 13, 90–100. Stanley, T. D. (2017). Limitations of PET-PEESE and other meta-analysis methods. Social Psychology and Personality Science, 8, 581–591. Stanley, T. D. (2019). Making meta-analysis credible: Supplemental materials. OSF. https://osf.io/eh974/ Stanley, T. D., Carter, E., & Doucouliagos, H. C. (2018). What meta-analyses reveal about the replicability of psychologi- cal research. Psychological Bulletin, 144, 1325–1346. Stanley, T. D., & Doucouliagos, H. C. (2014). Meta-regression approximations to reduce publication selection bias. Research Synthesis Methods, 5, 60–78. Stanley, T. D., & Doucouliagos, H. C. (2015). Neither fixed nor random: Weighted least squares meta-analysis. Statistics in Medicine, 34, 2116–2127. Stanley, T. D., & Doucouliagos, H. C. (2017). Neither fixed nor random: Weighted least squares meta-regression analysis. Research Synthesis Methods, 8, 19–42. Stanley, T. D., & Doucouliagos, H. C. (2022). Harnessing the power of excess statistical significance: Weighted and itera- tive least squares. Psychological Methods. Advance online publication. https://doi.org/10.1037/met0000502 Stanley, T. D., Doucouliagos, H. C., & Ioannidis, J. P. A. (2017). Finding the power to reduce publication bias. Statistics in Medicine, 36, 1580–1598. Stanley, T. D., Doucouliagos, H. C., & Ioannidis, J. P. A. (2022). Retrospective median power, false positive meta-analysis and large-scale replication. Research Synthesis Methods, 13, 88–108. Stanley, T. D., Doucouliagos, H. C., Ioannidis, J. P. A., & Carter, E. (2021). Detecting publication selection bias through excess statistical significance. Research Synthesis Methods, 12, 776–795. van Assen, M. A. L. M., & van Aert, R. C. M. (2015). Meta- analysis using effect size distributions of only statistically significant studies. Psychological Methods, 20(3), 293–309. Vankov, I., Bowers, J., & Munafò, M. R. (2014). On the per- sistence of low power in psychological science. Quarterly Journal of Experimental Psychology, 67, 1037–1040. White, H. A. (1980). Heteroscedasticity consistent covariance matrix estimator and a direct test of heteroscedasticity. Econometrica, 48, 817–818. Witte, E. H., & Zenker, F. (2017). Extending a multilab pre- registered replication of the ego-depletion effect to a research program. Basic and Applied Social Psychology, 39, 74–80.

######## 

Received: 23 August 2021 Revised: 4 March 2022 Accepted: 7 April 2022 DOI: 10.1002/jrsm.1562 R E S E A R C H A R T I C L E Location-scale models for meta-analysis Wolfgang Viechtbauer1 \| José Antonio Lopez-Lopez2 1Department of Psychiatry and Neuropsychology, Maastricht University, Maastricht, The Netherlands 2Department of Basic Psychology and Methodology, University of Murcia, Murcia, Spain Correspondence Wolfgang Viechtbauer, Department of Psychiatry and Neuropsychology, Vijverdalseweg 1, 6226 NB, Maastricht, The Netherlands. Email: wolfgang.viechtbauer\@ maastrichtuniversity.nl Abstract Heterogeneity is commonplace in meta-analysis. When heterogeneity is found, researchers often aim to identify predictors that account for at least part of such heterogeneity by using mixed-effects meta-regression models. Another potentially relevant goal is to focus on the amount of heterogeneity as a function of one or more predictors, but this cannot be examined with standard random- and mixed-effects models, which assume a constant (i.e., homoscedastic) value for the heterogeneity variance component across studies. In this paper, we describe a location-scale model for meta-analysis as an extension of the standard random- and mixed-effects models that not only allows an examination of whether predictors are related to the size of the outcomes (i.e., their location), but also the amount of heterogeneity (i.e., their scale). We present estimation methods for such a location-scale model through maximum and restricted maximum likelihood approaches, as well as methods for inference and suggestions for visualization. We also pro- vide an implementation via the metafor package for R that makes this model readily available to researchers. Location-scale models can provide a useful tool to researchers interested in heterogeneity in meta-analysis, with the potential to enhance the scope of research questions in the field of evidence synthesis. K E Y W O R D S heterogeneity, location-scale model, meta-regression, mixed-effects models Highlights • The observed effects or outcomes to be combined in a meta-analysis are often more variable than would be expected based on their sampling variability alone. This suggests that the underlying true effects or outcomes are heterogeneous. • Via appropriate meta-regression models, one can examine whether the size of the effects or outcomes tends to be larger under certain circumstances. • Standard meta-analytic models assume that the amount of heterogeneity is constant across circumstances. In the present paper, we describe a location- scale model for meta-analysis that allows researchers to examine not only This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes. © 2022 The Authors. Research Synthesis Methods published by John Wiley & Sons Ltd. Res Syn Meth. 2022;13:697–715. wileyonlinelibrary.com/journal/jrsm 697 698 VIECHTBAUER AND LÓPEZ-LÓPEZ whether the size of the effects or outcomes varies across circumstances, but also the amount of heterogeneity. • The model allows applied researchers to address entirely new research questions (e.g., for what types of studies are treatment effects more consistent?). 1 \| I N T R O D U C T I O N When a phenomenon of interest (e.g., the effectiveness of a treatment, the size of a group difference, or the associa- tion between two variables) has been examined across multiple studies, a meta-analysis can be conducted to synthesize the various findings. For this, we quantify the relevant results of each study in terms of an outcome or effect size measure (e.g., as raw/standardized mean dif- ferences, log risk/odds ratios, or raw or Fisher's r-to-z transformed correlation coefficients), so that the resulting observed outcomes or effects provide commensurable evidence about the phenomenon of interest and then apply appropriate statistical techniques to analyze these values.1 Due to sampling variability, the observed outcomes will differ across studies even if they estimate a common underlying parameter. However, in many cases, the observed outcomes are more variable than would be expected based on their sampling variability alone. This is typically interpreted as evidence for the presence of variability in the underlying true outcomes, a phenome- non commonly referred to as“heterogeneity” . 2 Random- effects models are then often used to estimate the amount of heterogeneity in the true outcomes, which is then incorporated into the analysis when estimating the aver- age true outcome.3,4 When heterogeneity is found, one can also try to examine if some predictor variables (also known as mod- erators or effect modifiers) are able to account for at least part of the heterogeneity in the outcomes. A subgroup meta-analysis can be used for this purpose by stratifying the observed outcomes according to a factor of interest.5 However, mixed-effects meta-regression models provide a more flexible approach, as they allow researchers to examine multiple predictors, both continuous and cate- gorical, within a single modeling framework.6,7 In a standard mixed-effects meta-regression model, one or more predictors are included in the model and their association with the size of the outcomes is exam- ined. The“residual heterogeneity” (i.e., the heterogeneity not accounted for by the predictors) is assumed to be homoscedastic. However, this assumption may be vio- lated in practice. Moreover, the amount of heterogeneity might actually vary systematically as a function of one or more predictors (which may be a different set of predic- tors than those related to the size of the outcomes) and this is something that cannot be examined by means of standard meta-regression models. Regression models that allow for the error variance to depend on predictor variables have been studied exten- sively in the past.8,9 These so-called“location-scale models” are also increasingly popular in the field of mul- tilevel modeling,10,11,12 and a tutorial for their implemen- tation in R and SAS in this context is available.13 In the meta-analytic context, location-scale models are seldom used, although their merits have been discussed and illustrated before using the sample sizes of the studies as a predictor for the amount of heterogeneity,14 and a Bayesian variant for categorical scale moderators with regularized parameters has also been proposed.15 As an illustration, consider a meta-analysis on the effectiveness of a psychological intervention that can be delivered either in groups or in an individual format. A common research question is whether both delivery for- mats yield similarly effective results. This question is related to the“location” part of the model (i.e., the out- come magnitude or size of the average effect) and is rou- tinely examined using meta-regression models. However, we could also raise the question whether both delivery formats lead to equally consistent results. For instance, individual therapy might achieve relatively similar (i.e., homogeneous) results across studies, regardless of the types of patients included or other contextual factors that might vary across studies. On the other hand, group therapy might be very effective for certain types of patients and circumstances, but less so for others, which would imply more heterogeneous findings for studies examining this delivery format. The latter question is related to the“scale” part of the model (i.e., outcome var- iability), which cannot formally be examined with stan- dard meta-regression models. Both outcome magnitude and outcome variability constitute relevant information for decision making, and this warrants the implementa- tion of location-scale models in meta-analysis. The purpose of the present paper is to describe the extension of the standard mixed-effects meta-regression model to a location-scale model and to illustrate the use of such a model with several examples with different types of predictor variables. The methods described are also 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ implemented in the R package metafor16 and we provide the data and code to replicate the illustrative analyses. The structure of the paper is as follows. In the next section, we present the model. We then provide some technical details about the estimation procedures and methods for making inferences about the parameters in the context of such models. We then present an illustra- tive example and conclude the paper with a general discussion. 2 \| M E T A - A N A L Y T I C M O D E L S Below, we briefly review the standard random- and mixed-effects models and then describe their extension in terms of the location-scale model. 2.1 \| Standard Random- and Mixed- Effects Models For a set of i¼ 1,…, k independent studies, let yi denote the observed value of the outcome measure of interest in the ith study. The standard random-effects model in meta-analysis is given by yi ¼ μ þ ui þ ei, ð1Þ where μ denotes the average true outcome in the popula- tion of studies, ui N 0, τ2 ð Þ is a normally distributed ran- dom effect that allows for heterogeneity in the underlying true outcomes (with τ2 denoting the between- study variance), and ei N 0, vi ð Þ is the normally distrib- uted sampling error of the ith estimate. The sampling (or within-study) variances (i.e., vi values) are assumed to be known constants.\* The random-effects model is actually a special case of the more general mixed-effects meta-regression model given by yi ¼ β0 þ β1xi1 þ… þ βpxip þ ui þ ei, ð2Þ where xi1, …, xip are the values of p moderator variables that may be related to the size of the average true outcome as specified by the model, β1, …, βp are the model coefficients that indicate how the average true out- come changes for a one-unit increase in the corr- esponding moderator variable, and β0 is the model intercept. Assumptions about ui and ei are the same as before, except that τ2 now denotes the amount of resid- ual heterogeneity, that is, variability in the true outcomes not accounted for by the moderator(s) included in the model. 699 2.2 \| Location-Scale Model Equation (2) defines a model that describes the relationship between one or multiple moderators and the size of the out- comes. Hence, in this model, moderators are assumed to be related to the“location” of the outcomes. Accordingly, we will refer to xi1, …, xip as “location variables” and to β0, …, βp as the corresponding“location coefficients”. However, there may also be a relationship between the moderators and the amount of heterogeneity in the outcomes. Hence, the “scale” (i.e., variance) of the outcomes may also be func- tion of one or multiple moderator variables. Accordingly, we will refer to the latter as“scale variables” . The standard random- and mixed-effects models do not allow for this possibility, since they assume that the amount of (residual) heterogeneity is constant (i.e., homoscedastic) across studies. This assumption can be relaxed by letting τ2 be a function of one or more scale variables. In particular, let τ2 i ¼ α0 þ α1zi1 þ… þ αqziq, ð3Þ where zi1, …, ziq are the values of q scale variables that may be related to the amount of heterogeneity and α1, …, αq are the corresponding“scale coefficients”, with α0 again denoting the intercept. A problem with (3) is the possibility that τ2 i can be negative for certain combinations of values for the scale variables and scale coefficients. To enforce that the vari- ance cannot become negative for any of the studies, we can use a model with a log link, so that ln τ2 i ¼ α0 þ α1zi1 þ… þ αqziq: ð4Þ Then τ2 i is given by exp α0 þ α1zi1 þ þ αqziq , which is guaranteed to be positive (or possibly indistinguishable from zero if the values of the scale variables and scale coefficients lead to a very negative value of ln τ2 i for a particular study). Note that the standard random- and mixed-effects models are just special cases of the location-scale model where the scale part of the model only includes an intercept term, so that τ2 ¼ α0 or τ2 ¼ exp α0 ð Þ, depending on the link function used. 2.3 \| Maximum Likelihood Estimation The log-likelihood for the location-scale model with a log link is given by ll β, α ð Þ ¼ k ln 2π ð Þ 1 ln j M j 1 2 2 2 y Xβ ð Þ0W y X β ð Þ, ð5Þ 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 700 where M¼ V þ diag exp Zα ð Þ ð Þ, W¼ M 1 , y is the k 1 vector with the observed outcomes, V is the k k diago- nal matrix with the sampling variances, X is the k p þ 1 ð Þ model matrix containing the location variables (with the first column equal to a vector of 1's for the intercept), β is the corresponding p þ 1 ð Þ 1 vector with the location coefficients, Z is the k q þ 1 ð Þ model matrix with the scale variables (again with the first column equal to a vector of 1's), α is the q þ 1 ð Þ 1 vector with the scale coefficients, and diag() is a function that turns a vector into a diagonal matrix. By setting X to only a col- umn of 1's, we obtain a random-effects model, but with heteroscedastic between-study variances. By setting Z to only a column of 1's, we obtain the standard random/ mixed-effects model (with homoscedastic between-study variance) as a special case. Note that (5) is the straightfor- ward generalization of the log-likelihood function for the standard random- and mixed-effects meta-regression models,17,18 where the only change is that M is no longer diagonal with elements vi þ τ2, but with elements vi þ τ2 i: Maximum likelihood estimates (MLEs) of β and α can be obtained by maximizing (5) simultaneously over the p þ q þ 2 location and scale coefficients. The optimization problem can be simplified by noting that b β¼ X 0WX ð Þ 1X 0Wy ð6Þ is the MLE of β for a given vector of α. Hence, after substitutingb β for β in (5) and some algebraic simplifica- tion, we can construct the profile log-likelihood llP α ð Þ ¼ k ln 2π ð Þ 1 ln j M j 1 2 2 2 y0Py, ð7Þ where P¼ W WX X 0WX ð Þ 1X 0W: ð8Þ Now (7) only depends on α (through M, W, and hence P), which reduces the optimization problem to one involving only the q þ 1 scale coefficients. Quasi-Newton or Nelder–Mead type algorithms can be used for this purpose,19 which avoids the need to compute the Hessian or information matrix, as would be needed for the Newton–Raphson or Fisher scoring algorithms. The approach described above yields the MLE of α for model (4), which we denote asb α. Onceb α has been obtained, we can compute the MLE of β with (6), with W¼ M 1 as before where M¼ V þ diag exp Zb α ð Þ ð Þ. The same approach can also be used to obtain the MLE of α for model (3) that uses an identity link by VIECHTBAUER AND LÓPEZ-LÓPEZ letting M¼ V þ diag Zα ð Þ. However, then extra steps must be taken when optimizing (7) over α to ensure non- negativity for all of the Zα values.† Linearly constrained optimization algorithms can be used for this purpose.19 Here, the feasible region for α is that set of values for which Zα ≥ 0. Again, onceb α has been obtained, we can compute the MLE of β with (6), where W¼ M 1 and now M¼ V þ diag Zb α ð Þ. 2.4 \| Restricted Maximum Likelihood Estimation MLEs of variance components are known to be negatively biased, while restricted maximum likelihood (REML) esti- mation yields approximately unbiased estimates.20,21,22,23 The same has been found for the ML and REML estima- tors of τ2 in the standard random-effects model.17 Accord- ingly, it may also be preferable to use REML estimation to estimate the scale coefficients for the location-scale model. The restricted log-likelihood is given by llR α ð Þ ¼ k p 1 ln 2π ð Þ þ 1 ln j X0X j 1 ln j M j 1 ln 2 2 2 2 j X 0WX j 1 2 y0Py, ð9Þ with all elements as defined previously. Note that (9) depends on α through M, W, and P, but no longer involves the location coefficients. However, once llR has been maximized over the the q þ 1 scale coefficients (either for the log or identity link model), we can again obtain estimates of the elements in β with (6). 2.5 \| Inference Once the ML or REML estimatesb α andb β have been obtained, making statistical inferences about the location and scale parts of the model is typically the next step in the analysis. Wald-type methods and methods based on the likelihood ratio of nested models can be used for this purpose and are described below. 2.5.1 \| Inference about the Location Part of the Model The variance–covariance matrix of the elements inb β can be estimated with Varb β h i¼ X0WX ð Þ 1 : ð10Þ 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ z ¼ Hence, we can conduct a Wald-type test of the null hypothesis H0 : βj¼ 0 (with j¼ 0,…, p) by computing b βj SEb βj h i, ð11Þ where SEb Varb βj h i¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ rand Varb βj h i βj h iis the corres- ponding (i.e., jth + 1) diagonal element of (10). Under H0, (11) follows asymptotically a standard normal distribu- tion based on which we can compute the p-value for the test. An approximate 95% confidence interval (CI) for βj can also be obtained withb βj 1:96 SEb βj h i: Multiple coefficients inb β can be tested simulta- neously by computing 1 b Qβ¼ β0 2 ½ Varb β h i 2 ½ b β 2 ½ , ð12Þ whereb β 2 ½ includes the set of location coefficients to be tested and Varb β h i 2 ½ contains the corresponding rows and columns from (10). Under H0 : β 2 ½ ¼ 0, (12) follows asymptotically a chi-square distribution with degrees of freedom equal to the number of coefficients tested. A common application of (12) is to test all location coefficients except for the model intercept b b b βp h i0 i:e:, β 2 ½ ¼ β1, …, , yielding an omnibus test of the location part of the model. The predicted average outcome for a particular com- bination of values for the location variables can be com- b puted withb yh ¼ xh β, where xh is either a particular row from X (yielding the fitted value,b yi, for the corresponding study) or contains some other combi- nation of values for the location variables. An approxi- mate 95% CI for a predicted/fitted value is then given ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ byb yh 1:96 xh Varb r: β h ix0 h 2.5.2 \| Inference about the Scale Part of the Model Estimating the variance–covariance matrix of the ele- ments inb α is not as straightforward. Although computa- tionally more demanding, we can make use of numerical differentiation24 to approximate the matrix of second derivatives (i.e., the Hessian) of llP α ð Þ or llR α ð Þ with 701 respect to the elements in α. Once the Hessian is obtained, the inverse of the negative Hessian matrix yields the estimated variance–covariance matrix of the scale coefficients, which we denote by Varb α ½ : Hence, a Wald-type test of the null hypothesis H0 : αj¼ 0 (with j¼ 0,…, q) can be conducted by computing b αj z ¼ , ð13Þ SEb αj where SEb αj is the square-root of the corresponding (i.e., jth þ 1) diagonal element of Varb a ½ . Under H0, (13) again follows asymptotically a standard normal dis- tribution. As before, we can also construct an approxi- mate 95% CI for αj withb αj 1:96 SEb αj . Similarly, multiple scale coefficients inb α can be tested simultaneously by computing 1 Qα ¼ b 0 α 2 ½ Varb α ½ 2 ½ b α 2 ½ , ð14Þ whereb α 2 ½ and Varb α ½ 2 ½ again include the rows (and col- umns) corresponding to the coefficients to be tested. Under H0 : α 2 ½ ¼ 0, (14) follows asymptotically a chi- square distribution with degrees of freedom equal to the number of coefficients tested. By including all scale coef- ficients except for the intercept in this test (i.e.,b b b α 2 ½ ¼ αq α1, …, 0), we can conduct an omnibus test of the scale part of the model. The predicted amount of (residual) heterogeneity for a particular combination of values for the scale variables can be computed withb 2 τ h ¼ exp zhb α ð Þ orb 2 τ h ¼ zhb α when using a log or identity link for the scale part of the model, respectively. Here, zh denotes either a particular row from Z (yieldingb 2 τ i ) or some other combination of values for the scale variables. A corresponding app- roximate 95% CI for τ2 h is then given by either exp zhb α 1:96ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ zh Varb p or zhb α ½ z0 α 1:96ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ h zh Varb p. α ½ z0 h Note that when using an identity link,b 2 τ h is only guaranteed to be non-negative when zh is a row from Z. Moreover, even then, the lower bound of the CI may be negative. While one could set negativeb 2 τ h values or CI bounds to 0, we can avoid these issues altogether by using the log link, since exponentiation guarantees non- negative predicted values and CI bounds in all cases. 2.5.3 \| Likelihood ratio tests and confidence intervals Likelihood ratio tests (LRTs) can also be used to compare models. For the LRT of one or multiple location/scale 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 702 coefficients, let llb α denote the maximized log- β, b likelihood under the full model and llb α0 the maxi- β0, b mized log-likelihood under the reduced model where the location/scale coefficients to be tested are constrained to zero (which is equivalent to fitting a model where we remove from X and/or Z the columns that correspond to the location and/or scale coefficients tested). Under the null hypothesis that the corresponding true values of the location/scale coefficients are equal to zero, the LRT statistic X2 ¼ 2 llb α ð15Þ β0, b α0 llb β, b then follows asymptotically a chi-square distribution with degrees of freedom equal to the number of coefficients tested. It is also possible to test scale coefficients in this man- ner when using REML estimation. Here, we let llRb α ð Þ and llRb α0 ð Þ denote the maximized restricted log-likelihood under the full and reduced model, respectively. Then X2 α ð Þ ð Þ ð16Þ R ¼ 2 llRb α0 ð Þ llRb follows asymptotically a chi-square distribution with degrees of freedom equal to the number of scale coeffi- cients tested. For the standard random-effects model, Hardy and Thompson25 describe how to“invert” the LRT to con- struct profile likelihood CIs for μ and τ2 (or a confidence region for both parameters jointly). The same idea can be generalized to the present model, yielding profile likeli- hood CIs for particular model coefficients (or a confi- dence region for multiple coefficients). This approach is especially advantageous for the scale coefficients, since their sampling distribution may not be normal (which is implicitly assumed by (13) and the corresponding Wald- type CI) and we will therefore focus on the construction of profile likelihood CIs for this purpose. Let llP e α ð Þ denote the maximized profile log-likelihood when one or multiple scale coefficients are constrained not to zero, but to arbitrary values and χ2 r,:95 the 95th qua- ntile of a chi-square distribution with r degrees of free- dom, where r denotes the total number of scale parameters that were constrained. Then the set of alle α values that satisfy llP e α ð Þ ≥ llP e α ð Þ χ2 r,:95=2 ð17Þ denotes a 95% CI (or confidence region) for the coeffi- cients that were constrained. Similarly, letting llR e α ð Þ denote the maximized restricted log-likelihood when one VIECHTBAUER AND LÓPEZ-LÓPEZ or multiple scale coefficients are constrained to arbitrary values, then the set of alle α values that satisfy llR e α ð Þ ≥ llR e α ð Þ χ2 r,:95=2 ð18Þ denotes a 95% CI (or confidence region) for the con- strained scale coefficients under REML estimation. 2.5.4 \| Small-Sample Performance As noted above, the distributional assumptions underly- ing the inferential methods presented here are based on asymptotics, that is, they rely on large-sample approxima- tions. To be precise,“large-sample” in the present context primarily refers to the number of studies included in the analysis (although as noted in the footnote in section 2.1, the within-study sample sizes also need to be sufficiently large so that the sampling variances can be treated as approximately known). Moreover, when the model includes categorical predictors, then the number of stud- ies within each category needs to be sufficiently large for the approximations to hold. The methods described in section 2.5.1 for making inferences about the location part of the model are identi- cal to those used in standard mixed-effects meta- regression models.26,27 However, based on simulation studies in this context,18 we know that the tests and CIs may not have nominal properties (i.e., their actual Type I error and coverage rates can deviate from the chosen level), especially when k is small. The Knapp-Hartung method28 is a well known improvement over the stan- dard Wald-type methods, leading to tests and CIs with close to nominal performance.18 A generalization of the method is also possible for location-scale models. Let s2 ¼ Pk b yi ð Þ2= k p 1 ð Þ where i¼1wi yi wi ¼ 1= vi þb 2 i . Now using Varb τ β h i¼ s2 X0WX ð Þ 1 as the variance–covariance of the elements inb β, the test statis- tic (11) then follows an approximate t-distribution with k p 1 degrees of freedom under H0, while the 95% CI for βj is obtained withb βj t :975; k p 1 SEb βj h i, where t :975; k p 1 denotes the 97.5th quantile of a t-distribution with the same degrees of freedom. The test of multiple coefficients is then conducted with Fβ¼ Qβ=m, which fol- lows an approximate F-distribution with m and k p 1 degrees of freedom under H0, where m denotes the num- ber of coefficients tested. Finally, to construct the 95% CI for a predicted average outcome, we then use ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ b yh t :975; k p 1 xh Varb r. These results follow directly β h ix0 h from those given by Knapp and Hartung.28 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ An analogous generalization of the methods given in section 2.5.2 for making inferences about the scale part of the model is not currently available. We can, however, heuristically still compare the test statistic (13) to a t-dis- tribution, now with k q 1 degrees of freedom and con- struct the CI for αj accordingly. Similarly, we can use Fα ¼ Qα=m to test multiple scale coefficients, now letting m denote the number of scale coefficients tested, and use an F-distribution with m and k q 1 degrees of freedom as a reference. Finally, in the 95% CI for τ2 h, we simply replace 1:96 with t :975; k q 1. In essence, these are analo- gous heuristic adjustments that have previously been considered in the context of standard random-effects and meta-regression models.29,30 It is currently unknown how well the standard or adjusted methods perform in small samples and how large the number of studies needs to be for the methods to have nominal properties. However, given that accurate estimation and inferences about the amount of heteroge- neity in standard random-effects models is already a diffi- cult endeavor to begin with,17,31,32 we suspect that k will need to be fairly large for the methods to have nominal properties. Therefore, at the moment, we would caution against the application of location-scale models in small meta-analyses. 2.6 \| Profile Likelihood Plots Fitting location-scale models is a non-trivial optimization problem, especially when the model includes a large number of scale variables. The q þ 1 dimensional surface of the profiled log-likelihood (7) or the restricted log-likelihood (9) may involve ridges, local optima, and saddle points, which can lead to convergence to a non- optimal solution. To obtain some reassurance that llPb α ð Þ or llRb α ð Þ really does correspond to its respective global maximum, we can make use of profile likelihood plots for each of the scale coefficients in the model. To construct such a plot for a particular scale coefficient αj, we fix the coefficient to some value nearb αj and maxi- mize (7) or (9) over the remaining scale coefficients. By repeating this process for a range of values aroundb αj, we can examine how llP α ð Þ or llR α ð Þ changes as a function of αj (i.e., we construct a profile of (7) or (9) along the dim- ension corresponding to αj). Note that this is in essence the same process that is involved in finding a profile like- lihood CI for αj as described in the previous section. The profile likelihood function constructed in this manner should have a peak atb αj, indicating that llP α ð Þ or llR α ð Þ is really maximized along the dimension corresponding to αj within the range of αj values exam- ined. By constructing such profiles for each scale 703 parameter, we can check that the respective likelihoods are maximized along each dimension, at least within the vicinity ofb α.‡ See Raue et al.33 for further details on the use of profile likelihoods for checking on the identifiability of parameters in complex models. 2.7 \| Prediction Intervals For the standard random-effects model (1), Raudenbush26 suggested to computeb μ 1:96b τ as a “plausible value interval” that should contain approximately 95% of the true outcomes. A similar type of interval, referred to as a “credibility interval”, was proposed by Hunter and Schmidt34 to quantify the degree to which the underlying true outcomes may vary over studies. How- ever, these intervals ignore the uncertainty inb μ and hence an improved interval could be computed with ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ b μ 1:96 b q.§ Intervals of this type have also τ 2 þ SEb μ ½ 2 been referred to as“prediction intervals” (PI),35 as they can also be interpreted as the range for the predicted true outcome in a new study. Given that this term has also found its way into popular textbooks on meta-analysis36 and is based on similar concepts in regression modeling,37 we will adopt the same terminology below. To compute PIs in the context of a location-scale model, we need to specify the values of the location and scale variables. In particular, recall that the predicted average outcome for a particular combination of values b for the location variables is given byb yh ¼ xh β, whileb 2 τ h ¼ exp zhb α ð Þ (orb 2 τ h ¼ zhb α when using an identity link) yields the predicted amount of (residual) heterogeneity for a particular combination of values for the scale variables. Hence, an approximate 95% PI for the true outcomes of studies (or a future study) at the chosen values of xh and ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ zh is given byb 2 yh 1:96 b h þ xh Varb r, withb τ β h ix0 2 τ h h as defined above. When using the generalization of the Knapp-Hartung method described earlier, we replace 1:96 with t :975; k p 1. 2.8 \| Visualization The results of a meta-regression model involving a numerical/quantitative predictor can be visualized by plotting the observed outcomes on the y-axis against the values of the predictor on the x-axis and adding the regression line based on the model (with or without corresponding CI and/or PI bands) to such a plot.38,39 Typically, the outcomes are drawn proportional in size to 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 704 VIECHTBAUER AND LÓPEZ-LÓPEZ some measure of their precision (e.g., 1=vi) or the model AIC¼ 2ll þ 2 p þ q þ 2 ð Þ, ð19Þ weights (i.e., the diagonal elements of W , which are equal to wi ¼ 1= vi þb 2 i for location-scale models). Given τ where ll is either llP or llR for ML or REML estimation, their appearance, such scatter plots are also at times respectively, and p þ q þ 2 corresponds to the total num- referred to as“bubble plots”. This type of graph is equally ber of parameters of the location-scale model. Heuristi- applicable to visualize the results from the location part cally, we can regard the AIC as a measure that penalizes of a location-scale model involving a quantitative loca- the fit of a model (as indicated by its \[restricted\] log-like- tion variable. On the other hand, for a categorical predic- lihood) for its complexity (as indicated by the number of tor, one can simply add the estimated average outcomes included parameters). As expressed in (19), models with for the various levels of the predictor (i.e., the subgroups lower AIC values strike a better balance between fit and defined by the predictor) to a standard forest plot.39 complexity and are therefore to be preferred. For illustrating the results from the scale part of An alternative is the Bayesian Information Criterion a model, we suggest the following visualization. First, (BIC),45 which is given by let H¼ X X 0WX ð Þ 1X0W denote the hat matrix and hi the ith diagonal element thereof. Furthermore, let ei ¼ BIC¼ 2ll þ 2 p þ q þ 2 ð Þln k ð Þ, ð20Þ b yi yi denote the observed residual of the ith study which, under the assumptions of the model, can be where k¼ k for ML and k¼ k p 1 for REML estima- shown to have expectation 0 and variance tion. When k ≥ 8, the BIC imposes a greater penalty for Var ei ½ ¼ 1 hi ð Þ vi þ τ2 i . Hence, we can useb 2 τ i ¼ the model complexity compared to the AIC and therefore e2 i = 1 hi ð Þ vi as an estimate of τ2 i (setting negativeb 2 τ i tends to favor simpler models. Similarly, the corrected values to 0). We can therefore plot these estimates against AIC is given by the values of a quantitative scale variable as an analogue to the bubble plot described above. As above, the regres- AICc¼ 2ll þ 2 p þ q þ 2 ð Þ k sion line, now for the predicted amount of heterogeneity k p þ q þ 2 ð Þ 1 , ð21Þ as a function of the predictor, can be added to such a fig- ure (with or without a corresponding CI band). For a cat- where k¼ max k, p þ q þ 4 ð Þ for ML and k¼ egorical scale variable, differences in the amount of max k p 1, p þ q þ 4 ð Þ for REML estimation, which heterogeneity across subgroups can again be visualized as ensures that the additional multiplicative term is ≥ 1 and part of a forest plot, for example by showing the different hence again implies a greater penalty for the number of PIs for the various subgroups defined by the predictor. parameters compared to the AIC.46 Strictly speaking, models that differ in terms of their fixed effects (i.e., location variables) should not be com- 2.9 \| Model Selection pared with respect to their restricted log-likelihoods,47,48 which would imply that information criteria computed In practice, one is often faced with a large number of based on REML estimation would only be valid for model potentially relevant location and/or scale variables one selection when comparing models including different could include in a model. The problem of finding those scale but the same set of location variables. However, predictors that are truly related (if any) to the location recent evidence suggests that information criteria com- and/or scale of the outcomes can therefore be framed as puted based on REML estimation may even serve as a a model selection problem.40 While it is still common model selection tool when their fixed effects differ.40,49 practice to examine one predictor at a time in a series of Regardless of this issue, further research is needed to univariate meta-regression models,41 this approach examine the performance of information-theoretic increases the risk of finding spurious relationships due to methods for model selection in the present context. the fact that predictors are often correlated. Fitting models which include multiple predictors of interest can mitigate this problem at least to some extent.42 The use of information-theoretic methods43 for model selection in the context of meta-regression analyses was also recently explored and might constitute a promising alternative to the use of null-hypothesis significance testing.40 For this, we compute, for a set of potentially plausible models, one of several different information criteria such as the Akaike Information Criterion (AIC),44 which is given by 2.10 \| Implementation Details The option to fit location-scale models was recently added in an update to the metafor package16 for R50 as part of the rma() function. Maximization of the pro- filed log-likelihood (7) or the restricted log-likelihood (9) (for ML and REML estimation, respectively) is accom- plished by default using the quasi-Newton algorithm 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ 705 implemented in the nlminb() function,51 but the user also The standard random-effects model yields an esti- has the option to choose from a wide variety of alterna- mated overall effect ofb μ¼ 0:22 (95% CI: 0:12 to 0:32, tive optimization routines should convergence issues p \< 0:001), suggesting that intervention groups obtained arise. When using an identity link, constrained optimiza- on average higher academic achievement scores than tion using the Nelder–Mead (downhill simplex) method52 control groups. However, the between-study variance is used in combination with an adaptive barrier algo- estimate ofb 2 τ ¼ 0:050 leads to a 95% PI aroundb rithm53 as implemented in the constrOptim() function to μ from 0:24 to 0:68, which reveals substantial heterogeneity in ensure non-negativity of Zα. The numDeriv package,54 the effectiveness of such interventions across studies. which provides accurate methods for numerical differen- Figure 1 shows a forest plot of the individual effect size tiation using Richardson extrapolation, is used to obtain estimates with the results from the random-effects model the Hessian matrix of the scale coefficients, from which at the bottom (the dotted interval around the summary their variance–covariance matrix is estimated. The output polygon indicates the PI bounds). The results from the for a fitted model includes Wald-type tests and CIs for location-scale model will be discussed further below. the location and scale coefficients,¶ while LRTs and pro- As a quick check of the routines, we can also fit the stan- file likelihood CIs (the latter only for the scale coeffi- dard random-effects model as a location-scale model by setting cients) can be obtained using the anova() and confint() X and Z both to column vectors of 1's. Doing so yields functions, respectively. Model identifiability can be the same estimate and CI for μ and an estimate ofb checked by drawing profile likelihood plots with the pro- α0 ¼ 2:997 (with SEb α0 ½ ¼ 0:4603) and therefore the model file() function and fit statistics (including the AIC, BIC, impliesb 2 τ ¼ exp 2:997 ð Þ ¼ 0:050 as above. An interesting and AICc) can be obtained with the fitstats() function. feature of this approach is that a 95% CI for τ2 can be Finally, the predict() function can compute the predicted readily constructed with exp 2:997 2:01 0:4603 ð Þ ¼ average outcome (with CI and PI) for a particular combi- 0:020, 0:126 ð Þ (where t :975; 47 ¼ 2:01), although it remains nation of values for the location variables and the to be examined how this CI compares (in terms of cover- predicted amount of (residual) heterogeneity for a partic- age and width) to other methods for constructing CIs for ular combination of values for the scale variables. τ2 in the context of the random-effects model.32,57 Next, we explored the association of two predictors with the size (i.e., location) and amount of heterogeneity 3 \| I L L U S T R A T I V E E X A M P L E (i.e., scale) of the outcomes. As an example of a quantita- tive predictor, we included the total sample size of each In this section, we demonstrate the application of location- scale models using a dataset readily available in the met- afor package. In this illustration, we model the scale part using a log link, use REML estimation (except when otherwise noted), and report Wald-type CIs for both the location and scale parts of the models (using the Knapp- Hartung generalization we described in section 2.5.4 for drawing inferences about location coefficients and the approximate t- and F-distributions for inferences about scale coefficients). We also illustrate the use profile likeli- hood plots and CIs for the scale coefficients. The analysis code can be found at https://osf.io/53mtg/. Bangert-Drowns et al.55 integrated the results from 48 studies examining the effectiveness of school-based interventions to improve educational achievement. Each study compared an experimental group of students who received an intervention focused on writing tasks (experi- mental group) against another group receiving conven- tional instruction (control group) with respect to some measure of academic achievement (e.g., final grade, an exam/quiz/test score). The outcome measure was the standardized mean difference (with positive scores favor- ing the intervention group),56 which we corrected for its small-sample bias. **study (range 16–542, with a mean and median of 116 and 68 participants, respectively) in the model, which we rescaled for interpretation purposes for the analyses (keeping the original scale for graphical display), so that the location and scale parts of the model can be written as yi ¼ β0 þ β1 ni=100 ð Þ and ln τ2 i ¼ α0 þ α1 ni=100 ð Þ, respectively. We also examined a categorical predictor, namely the subject matter that was taught in each study (mathematics: 28 studies; science: 9 studies; social sci- ence: 11 studies). This predictor was incorporated into the model as two dummy variables, one for science and the other for social science subjects (and hence using math as the reference category), resulting in the model yi ¼ β0 þ β1scii þ β2soci for the location part and ln τ2 i ¼ α0 þ α1scii þ α2soci for the scale part. We first fitted two separate models testing the association of each pre- dictor with both the location and scale of the outcomes, and then ran an additional analysis incorporating both into a model with multiple predictors, that is, yi ¼ β0 þ β1 ni=100 ð Þ þ β2scii þ β3soci for the location part and ln τ2 i ¼ α0 þ α1 ni=100 ð Þ þ α2scii þ α3soci for the scale part. The model with sample size as predictor provided evi- dence of a negative association with the size of the 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 706 VIECHTBAUER AND LÓPEZ-LÓPEZ F I G U R E 1 model (including the study subject as predictor) shown. Forest plot of the studies from Bangert-Drowns et al.55 with the results from the random-effects model and the location-scale outcomes (b β1 ¼ 0:055, 95% CI: 0:095 to 0:015, p¼ :008) and weaker evidence of a negative association with the amount of heterogeneity (b α1 ¼ 0:917, 95% CI: 1:952 to 0:117, p¼ 0:081). Therefore, studies with larger sample sizes tended to yield smaller (and maybe more homogeneous) outcomes. These associations are shown in the bubble plots in Figure 2. In Figure 2a, we included both the CI and PI bands around the regression line, the latter illustrating the shrinking of the amount of heterogeneity for larger studies. This is also what Figure 2b shows, in terms 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ 707 F I G U R E 2 Bubble plots showing the association between the sample size and the location and scale parts of the model in the example of Bangert- Drowns et al.55 of the predicted value of τ2 as a function of the sample size (with corresponding CI for the predicted values). With regards to subject type, the estimated aver- age effects and between-study variances for the three subject categories are presented at the bottom of Figure 1. The estimated average effect for studies focused on social science subjects wasb β0 þb β2 ¼ b μsoc ¼ 0:08 (95% CI: 0:04 to 0:19, p¼ 0:18), as opposed tob β0 þ b β1 ¼ b μsci ¼ 0:22 (95% CI: 0:22 to 0:67, p¼ 0:31) for sci- ence studies andb β0 ¼ b μmat ¼ 0:25 (95% CI: 0:14 to 0:36, p \<:001) for math studies. The omnibus test for the location part of the model (i.e., H0 : β1 ¼ β2 ¼ 0) yielded weak evidence of an association (Fβ 2, 45 ð Þ ¼ 2:43, p¼ 0:099). However, hypothesis tests for specific location coefficients showed evidence that social science studies reported on average effect size estimates of smaller magnitude than math studies (b β2 ¼ 0:17, 95% CI: 0:33 to 0:01, p¼ 0:034). Similarly, the omnibus test for the scale part (i.e., H0 : α1 ¼ α2 ¼ 0) provided some evidence of an association between subject type and the amount of heterogeneity in the outcomes (Fα 2, 45 ð Þ ¼ 3:32, p¼ 0:045). In particular, studies focused on science subjects yielded more heterogeneous outcomes (expb α0 þb α1 ð Þ ¼b 2 τ sci ¼ 0:306, 95% PI aroundb μsci from 0:97 to 1:42) than math studies (expb α0 ð Þ ¼b 2 τ mat ¼ 0:030, 95% PI aroundb μmat from 0:12 to 0:61) and social sci- ence studies (expb α0 þb α2 ð Þ ¼b 2 τ soc ¼ 0:000, 95% PI around b μsoc from 0:04 to 0:19). 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 708 VIECHTBAUER AND LÓPEZ-LÓPEZ T A B L E 1 Multiple meta-regression results using the data from Bangert-Drowns et al.55 Coefficientb β 95% CI forb βb α 95% CI forb α 95% PLCIa forb α Intercept 0:344 0:210 to 0:478 3:102 5:100 to 1:105 \< 8 to 1:276 Sample Size 0:058 0:099 to 0:018 0:539 1:682 to 0:604 7:159 to 0:551 Sciences vs. Math 0:080 0:487 to 0:327 2:233 0:122 to 4:344 0:332 to \> 10 Social Sciences vs. Math 0:109 0:274 to 0:057 0:401 2:425 to 3:227 \< 10 to \> 10 aPLCI= profile likelihood confidence interval. F I G U R E 3 Bangert-Drowns et al.55 Profile likelihood plots for the scale coefficients in the model with multiple location and scale predictors in the example of 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ 709 Of note, the estimates of the average effect and between-study variance for each subject type from the previous location-scale model can also be obtained by fitting separate random-effects models for each category of the moderator. Doing so leads to estimates ofb μmat ¼ 0:25 andb 2 τ mat ¼ 0:030 for math studies,b μsci ¼ 0:22 and b 2 τ sci ¼ 0:306 for science studies, andb μsoc ¼ 0:08 andb 2 τ ¼ soc 0:000 for social science studies, respectively. This illus- trates the equivalence between separate random-effects and location-scale models when a single categorical mod- erator is considered (but only in this special case).†† Table 1 presents the results of the model including sample size and subject type as predictors for both the location and scale of the outcomes. For illustration pur- poses and due to the increasing complexity of the model, Figure 3 presents profile likelihood plots for the scale coefficients in the model, which do not suggest estima- tion problems.‡‡ Furthermore, in addition to the Wald- type CIs reported throughout the paper, we also report in Table 1 profile likelihood CIs for the scale parameters (calculated with Equation 18). However, due to the flat- ness of some of the likelihood profiles for values of αj fur- ther away fromb αj (see Figure 3), some of the bounds cannot be obtained exactly. Irrespective, both interval types lead to the same sta- tistical conclusions, and hence for simplicity we focus on the Wald-type CIs for the result interpretation. The omni- bus tests of the location and scale coefficients (i.e., H0 : β1 ¼ β2 ¼ β3 ¼ 0 and H0 : α1 ¼ α2 ¼ α3 ¼ 0) showed some evidence of associations for both parts (Fβ 3, 44 ð Þ ¼ 3:44, p¼ 0:025 and Fα 3, 44 ð Þ ¼ 2:70, p¼ 0:057, respectively). After controlling for subject type, there was still evidence of an association between the sample size of the studies and the size of the outcomes (b β1 ¼ 0:058, 95% CI: 0:099 to 0:018, p¼ 0:006) but not with the amount of heterogeneity (b α1 ¼ 0:539, 95% CI: 1:682 to 0:604, p¼ 0:35). Tests of H0 : β2 ¼ β3 ¼ 0 and H0 : α2 ¼ α3 ¼ 0 can be used to test for differences between the subject types after controlling for sample size. For the location part, the test indicated no evidence of an association between subject type and the size of the outcomes (Fβ 2, 44 ð Þ ¼ 0:91, p¼ 0:41), whereas the test result for the scale part of the model suggested some weak evidence of an association with the amount of het- erogeneity (Fα 2, 44 ð Þ ¼ 2:39, p¼ 0:10). When examining the individual scale coefficients, there was evidence that interventions focused on science subjects yielded more heterogeneous outcomes than those focused on math subjects (b α2 ¼ 2:233, 95% CI: 0:122 to 4:344, p¼ 0:039). The previous model can be used to make predictions for μ and τ2 in future studies. For the location part, the multiple meta-regression model predicts a value ofb μ¼ 0:32 (95% PI: 0:08 to 0:71) for a study focused on math subjects with 50 participants, but the predicted effect decreases tob μ¼ 0:29 (95% PI: 0:06 to 0:63) andb μ¼ 0:26 (95% PI: 0:04 to 0:56) as the sample size increases to 100 and 150 participants, respectively. With regards to the scale part, keeping the sample size fixed at 100 partici- pants, the model predicts an amount of heterogeneity of b 2 τ ¼ 0:026 (95% CI: 0.006 to 0.121) for math-focused inter- ventions, which increases tob 2 τ ¼ 0:039 (95% CI: 0.004 to 0.437) for social science and tob 2 τ ¼ 0:245 (95% CI: 0:060 to 1:001) for science subjects. In the models above, the same predictors were used for the location and scale parts. To illustrate that this is not a requirement, we fitted a model with sample size as a location moderator and subject type as a scale modera- tor, that is, yi ¼ β0 þ β1 ni=100 ð Þ for the location part and ln τ2 i ¼ α0 þ α1scii þ α2soci for the scale part. Results in Table 2 show evidence of a negative association between sample size and the magnitude of the outcomes (b β1 ¼ 0:062, 95% CI: 0:116 to 0:008, p¼ 0:026). Fur- thermore, there was evidence that science studies yielded more heterogeneous outcomes than math studies (b α1 ¼ 2:597, 95% CI: 0:529 to 4:666, p¼ 0:015), whereas no significant difference was found between social sci- ence and math studies (b α2 ¼ 0:520, 95% CI: 2:739 to 3:779, p¼ 0:75). Since this model is nested within the model that includes both sample size and subject type in the location and scale parts of the model, we can therefore also con- duct a LRT, examining if the full model (including both predictors in both parts) provides a significantly better fit than the model that only includes sample size as a T A B L E 2 et al.55 Multiple meta-regression results with different predictors for the location and scale parts, using the data from Bangert-Drowns Coefficientb β 95% CI forb βb α 95% CI forb α 95% PLCIa forb α Intercept 0:319 0:190 to 0:448 3:957 5:511 to 2:402 11:217 to 2:718 Sample Size 0:062 0:116 to 0:008 Sciences vs. Math 2:597 0:529 to 4:666 0:654 to 9:856 Social Sciences vs. Math 0:520 2:739 to 3:779 \< 10 to 7:700 aPLCI= profile likelihood confidence interval. 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 710 VIECHTBAUER AND LÓPEZ-LÓPEZ T A B L E 3 Log-likelihoods and fit criteria values for the various models fitted using the data from Bangert-Drowns et al.55 Location Scale Method Sample Size Subject Type Sample Size Subject Type logLik AIC BIC AICc ML 18.26 40.52 44.27 40.79 ✓ ✓ 13.24 34.48 41.96 35.41 ✓ ✓ 13.20 38.40 49.62 40.45 ✓ ✓ ✓ ✓ 10.08 36.16 51.13 39.86 ✓ ✓ 12.50 35.00 44.35 36.43 REML 18.49 40.99 44.69 41.26 ✓ ✓ 14.65 37.30 44.62 38.28 ✓ ✓ 13.99 39.97 50.81 42.18 ✓ ✓ ✓ ✓ 11.89 39.78 54.06 43.90 ✓ ✓ 13.55 37.10 46.24 38.60 location moderator and subject type as a scale moderator. Since the two models differ in terms of their location coefficients, we must refit the two models using ML esti- mation for the LRT to be meaningful. After doing so, (15) yields X2 ¼ 4:83 based on 3 degrees of freedom, resulting in p¼ 0:18 and hence no statistically significant evidence that the full model provides a better fit. To illustrate the use of information criteria for model selection, Table 3 shows the log-likelihood, AIC, BIC, and AICc values computed based on ML and REML esti- mation for all models considered above. All criteria favor the model including sample size in the location and scale parts of the model regardless of the estimation method used. The only exception to this was the AIC computed based on REML estimation, which was lower for the model including sample size in the location and subject type in the scale part of the model, although only by a thin margin. 4 \| D I S C U S S I O N In this paper, we have described a location-scale model for meta-analysis as an extension of the standard random- and mixed-effects models that not only allows an examination of whether predictors are related to the size of the outcomes (i.e., their location), but also the amount of heterogeneity (i.e., their scale). Together with a description of the methods for fitting and drawing infer- ences based on this model and an example illustrating its use, we have also provided an implementation via the metafor package for R that makes this model readily available to researchers. Of note, the use of this model does not require any additional information beyond what is necessary for fitting standard meta-regression models (except if hypotheses concerning the scale part involve variables that have not already been collected for the pur- poses of a standard moderator analysis). At the same time, we want to emphasize that guide- lines and caveats related to standard meta-regression analyses38,41,58 are equally applicable when examining scale variables. In particular, researchers should formu- late a priori hypotheses to motivate the examination of the scale variables and why/how they might be related to the amount of heterogeneity in the outcomes. For exam- ple, if the specification of clinical guidelines has led to an increased consistency in how a particular treatment has been implemented over time, one could hypothesize that the results from more recent trials might tend to be more consistent (i.e., exhibit lower amounts of heterogeneity) than earlier trials. On the other hand, more recent studies might explore the generalizability of a treatment effect by examining its effectiveness in more diverse populations, which in turn might lead to increased heterogeneity. In either case, such hypotheses should be formulated before embarking on such analyses. Even when the analyses are pre-specified and hypothesis driven, the potential for making at least one Type I error increases with the number of predictors examined. Although not common practice in meta- regression analyses,41 researchers should consider the use of corrections for multiple testing to reduce the number of false positive associations. This, however, comes at the cost of decreased power to detect true asso- ciations. In fact, we suspect that the number of studies required for location-scale models to have sufficient power to detect associations between scale variables and the amount of heterogeneity is fairly high to begin with. This, however, needs to be examined further via simula- tion studies. 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ 711 It is also important to emphasize that such analyses (whether they concern location or scale variables) are purely observational and hence any associations found could be confounded by other variables not controlled for in the analyses.42 Hence, as is the case for standard meta- regression analyses,59 “synthesis-generated evidence” about scale variable associations should be treated with due caution. Finally, any associations found, either with respect to location or scale variables, reflect relationships that exist at the study level which does not imply that similar relationships exist at the participant level. For example, if the mean age of the participants is found to be positively related to the size of a treatment effect across studies, then this indicates that studies including on average older participants tended to find larger effects, but this does not imply that the treatment tended to be more effective for older participants within studies (this may or may not be true). We illustrate this idea schematically in Figure 4a, showing the results from 50 trials where indeed such a relationship at the study level is present (i.e., the points correspond to the mean age values and (A) (B) Treatment Effectiveness Treatment Effectiveness Age Age (C) (D) Treatment Effectiveness Treatment Effectiveness Age Age F I G U R E 4 Schematic illustrations of the between- and within-study relationship between the (mean) age of study participants and the treatment effects in a set of 50 hypothetical trials (see text for explanations). 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 712 the corresponding observed effects), but within studies, there is no relationship between the age of the partici- pants and the treatment effectiveness (i.e., the ovals rep- resent envelopes containing the raw data). In contrast, Figure 4b illustrates the opposite scenario, where no rela- tionship exists at the study level, but within studies the treatment is more effective for older participants. Similarly, if the mean age of the study participants is found to be positively associated with the amount of het- erogeneity in the studies, then this indicates that studies including older participants tended to yield more hetero- geneous results. We illustrate this scenario in Figure 4c, where we see increased between-study variance in the effects for studies with older participants. However, such a finding does not imply that the treatment effect varies more strongly for older participants within studies. This case is shown in Figure 4d, where treatment effectiveness indeed varies more strongly for older participants within studies (note the increase in variance in the raw data as a function of age). To properly examine such within-study relationships, studies would need to quantify these types of associations directly, for example by reporting the correlation between the age of the study participants and the observed treat- ment effects or their variability. Alternatively, one may be able to quantify within-study differences in treatment effects or their variability if the studies report subgroup results (e.g., for younger versus older participants). Ide- ally, if the raw data of the individual studies are available, then an individual participant data meta-analysis could also be conducted where between- and within-study rela- tionships can be properly disentangled.60 This would be equally true for relationships involving scale variables, in which case multilevel location-scale models10,11,12 would need to be used for the meta-analysis. On a related note, there has been an increased inter- est recently in meta-analyzing not only outcome mea- sures that quantify the central tendency (i.e., average) of a quantitative response variable, but also its variability within groups or group differences thereof.61,62,63 In other words, while a more“traditional” meta-analysis might for example synthesize estimates of the difference in the mean blood pressure of treatment groups receiving antihypertensive therapy versus control groups, a meta- analysis could also examine if the within-group variabil- ity (as measured, for example, by the variance or standard deviation of the blood pressure measurements) differs between treatment versus control groups (e.g., by computing the ratio of the two standard deviations for each study and, after applying a suitable normalizing and variance stabilizing transformation, synthesizing these outcomes). It should be noted that meta-analyses of this type are addressing a different question than what can be VIECHTBAUER AND LÓPEZ-LÓPEZ examined with the location-scale model we have described in the present paper, which is focused on the between-study variability of the outcomes (i.e., are the findings of studies more heterogeneous under certain conditions than others?).§§ Hence, while there is a differ- ence in purpose between these different approaches, they both shift (at least to some extent) attention away from questions about averages to questions about variances, opening up avenues for new insights. Moreover, as we have demonstrated in the illustrative example, variables used as predictors for the location and scale parts of the model do not have to coincide. There- fore, one could even consider a model containing no loca- tion variables at all (except for the intercept term, allowing the average outcome to differ from zero), plac- ing the focus entirely on an examination of scale vari- ables to investigate under what conditions the outcomes of studies are more or less heterogeneous within a partic- ular meta-analysis. Questions about differences in heterogeneity have been raised previously. In particular, a number of prior studies examined to what extent estimates of heterogene- ity (or some derivative measure such as I2) differ across meta-analyses.64,65,66,67,68 However, these studies com- pared measures of heterogeneity across entire meta- analyses (differing for example in terms of the effect size measure used or the types of outcomes or interventions studied), while the location-scale model described in the present paper allows for an examination of differences in heterogeneity across the studies included in a single meta-analysis. Conceptually closer to this idea was the study by IntHout et al.,69 who examined differences in estimates of τ2 for the larger versus smaller studies within individ- ual meta-analyses. Across 235 meta-analyses that had used the standardized mean difference as the outcome measure, they found that smaller studies (with a total sample size below roughly 50 participants) tended to yield an estimate of τ2 that was on average 3.11 times larger than the estimate of τ2 of larger studies (with more than 50 participants). This is in line with what we found in our illustrative example (see Figure 2b), showing a decrease in the amount of heterogeneity for larger stud- ies. In fact, the predicted value of τ2 for a sample size of 36 (the mean sample size of the smaller studies with less than 50 participants) wasb 2 τ ¼ 0:105, compared tob 2 τ ¼ 0:035 for a sample size of 156 (the mean sample size of the larger studies with more than 50 participants), yield- ing a ratio of 3, which is remarkably close to the ratio found by IntHout et al.69 By using a location-scale model, we could however avoid the arbitrary dichotomization of the studies into“small” versus “large” ones and directly model the relationship between τ2 and the sample sizes. 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ It needs to be emphasized that this finding is unrelated to what we expect to see in a funnel plot, namely a decrease in the variability of the estimates for larger studies (at least when the true outcomes are suffi- ciently homogeneous). This phenomenon is attributable to the decrease in the sampling (or within-study) vari- ance for larger studies and is a natural consequence of the consistency of the estimators used for calculating the observed estimates. However, the extent to which the amount of heterogeneity in the underlying true effects/ outcomes differs across smaller versus larger studies within a particular meta-analysis is an empirical question that needs to be examined on a case-by-case basis, irrespective of the general trend found by IntHout et al.69 The location-scale model we have described in the pre- sent paper assumes independence between the observed outcomes or effect size estimates included in the same analysis. This assumption is often violated in practice, for example when multiple effect size estimates (e.g., for dif- ferent response scales) are computed based on the same group of study participants, when multiple effect size esti- mates are computed by contrasting several different treat- ment groups against a common control group within at least some of the studies, or when the data have some other hierarchical structure (e.g., when multiple studies included in the meta-analysis were conducted by the same author or research lab).70,71,72,73 An appropriate analysis of such dependent estimates requires the use of more complex models, possibly including multiple random effects (e.g., for studies and estimates within studies) while accounting for potential covariance in the sampling errors of the estimates. One could extend such multilevel/ multivariate meta-analysis models to also include a scale model for each variance component (e.g., for the amount of between- and within-study heterogeneity), although this would increase the complexity considerably and require even more nuanced considerations as to the types of scale variables that may be associated with the various sources of variability. At the moment, the rma.mv() func- tion in the metafor package that can be used to fit multi- level and multivariate meta-analysis models has not been extended to allow for this possibility, although this could be considered in a future update. For now, one could cir- cumvent this issue by using subsets of the data that con- tain only independent estimates and/or data aggregated to a level at which the estimates can be assumed to be inde- pendent to fit location-scale models. Aside from some interesting applications, we hope that the present paper will spark further research into the statistical properties of location-scale models in the pre- sent context and further extensions. As we alluded to ear- lier, we suspect that the increased complexity of such models will require a sufficiently large number of studies 713 to yield accurate estimates especially for the scale part of the model. Under the usual regularity conditions, we can reason that the ML/REML estimates of location-scale models will be asymptotically fully efficient and that the size of tests and the coverage rate of CIs will be nominal when k is large, but the specific conditions under which such behavior holds will require examination. Still, we believe that location-scale models are a use- ful tool for researchers interested in exploring whether the amount of heterogeneity may differ as a function of one or multiple predictor variables within a meta-analy- sis, broadening the research questions that can be addressed in the field of evidence synthesis. C O N F L I C T O F I N T E R E S T The authors declare no potential conflict of interests. E N D N O T E S \* For many outcome or effect size measures, the sampling variances are a function of one or multiple unknown parameters, which in practice need to be estimated based on the sample characteristics. In this case, the sampling variances are not really known con- stants, but estimates themselves. However, as long as the sample sizes of the studies are not too small, the sampling variances can be treated as approximately known. † Technically, we only need to ensure that the diagonal elements of M (i.e., the vi þ τ2 i values) are positive, so that M can be inverted. However, since we may be interested in and want to interpret the τ2 i values themselves, we prefer to enforce non-negativity of the Zα values directly. ‡ Even if this is indeed the case, it is of course possible thatb α only corresponds to a local maximum and that the global maximum lies in some region of the likelihood surface even further away from llPb α ð Þ or llRb α ð Þ. § This interval still ignores the uncertainty inb τ 2. As a heuristic sug- gestion, Higgins et al.35 propose to improve on this further by using the 97.5th quantile of a t-distribution with k 2 degrees of freedom in place of 1:96. ¶ To avoid any potential confusion, we note that the omnibus test statistics Qβ and Qα are denoted as QM and QS, respectively, in the output, although when using the adjustments described in section 2.5.4, these omnibus tests are denoted as F statistics.** Bangert-Drowns et al.55 only report the total sample size of each study (ni), not the sizes of the experimental and control groups separately (i.e., n1i and n2i, respectively). We therefore assumed n1i ¼ n2i ¼ ni=2 for computing the sampling variances of the (bias-corrected) standardized mean differences. †† A slight difference will still arise with respect to the inferences about the location coefficients when applying the Knapp-Hartung method. In the location-scale model, the method involves a single scaling factor, s2, to adjust the variance–covariance matrix of the elements inb β and the degrees of freedom for the t-distribution are taken to be k p 1. On the other hand, when fitting sepa- rate random-effects models within each level of the categorical moderator, separate scaling factors are calculated within each 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License 714 VIECHTBAUER AND LÓPEZ-LÓPEZ level and the degrees of freedom are kl 1, where kl denotes the number of studies within level l of the moderator. ‡‡ However, note that the profile for α0 shows non-monotonic behavior for low values of α0. Hence, the value of α0 ≈ 4:887 corresponds to a local maximum. Fortunately, this did not pre- vent the optimization algorithm from finding the (presumably) global maximum atb α0 ≈ 3:102. §§ The location-scale model could however also be used to meta- analyze outcome measures that reflect such between-group dif- ferences in within-group variability. Location variables would then be used to examine if the size of such between-group differ- ences in variability are on average larger under certain circum- stances than others, while the scale part of the model would be used to examine if the amount of heterogeneity in such between- group differences is larger for certain types of studies versus others. D A T A A V A I L A B I L I T Y S T A T E M E N T The code and data that support the findings of this study are openly available at the Open Science Framework (https://osf.io/53mtg/). O R C I D Wolfgang Viechtbauer https://orcid.org/0000-0003- 3463-4063 José Antonio Lopez-Lopez https://orcid.org/0000-0002- 9655-3616 R E F E R E N C E S 1. Borenstein M, Hedges LV, Higgins JPT, Rothstein HR. A basic introduction to fixed-effect and random-effects models for meta-analysis. Res Synth Methods. 2010;1(2):97-111. 2. Thompson SG. Why sources of heterogeneity in meta-analysis should be investigated. Br Med J. 1994;309(6965):1351-1355. 3. DerSimonian R, Laird N. Meta-analysis in clinical trials. Con- trol Clin Trials. 1986;7(3):177-188. 4. Hedges LV. A random effects model for effect sizes. Psychol Bull. 1983;93(2):388-395. 5. Borenstein M, Higgins JPT. Meta-analysis and subgroups. Prev Sci. 2013;14(2):134-143. 6. Raudenbush SW, Bryk AS. Empirical Bayes meta-analysis. Journal of Educational Statistics. 1985;10(2):75-98. 7. Thompson SG, Sharp SJ. Explaining heterogeneity in meta- analysis: a comparison of methods. Stat Med. 1999;18(20):2693- 2708. 8. Cook RD, Weisberg S. Diagnostics for heteroscedasticity in regression. Biometrika. 1983;70(1):1-10. 9. Carroll RJ, Ruppert D. Transformation and Weighting in Regression. Chapman & Hall; 1988. 10. Hedeker D, Mermelstein RJ, Demirtas H. An application of a mixed-effects location scale model for analysis of ecological momentary assessment (EMA) data. Biometrics. 2008;64(2): 627-634. 11. Hedeker D, Mermelstein RJ, Demirtas H. Modeling between- subject and within-subject variances in ecological momentary assessment data using mixed-effects location scale models. Stat Med. 2012;31(27):3328-3336. 12. Li X, Hedeker D. A three-level mixed-effects location scale model with an application to ecological momentary assessment data. Stat Med. 2012;31(26):3192-3210. 13. Hedeker D, Nordgren R. MIXREGLS: a program for mixed- effects location scale analysis. J Stat Softw. 2013;52(2):1-38. 14. Bowater RJ, Escarela G. Heterogeneity and study size in random-effects meta-analysis. Journal of Applied Statistics. 2013;40(1):2-16. 15. Thompson CG, Becker BJ. A group-specific prior distribution for effect-size heterogeneity in meta-analysis. Behav Res Methods. 2020;52(5):2020-2030. 16. Viechtbauer W. Conducting meta-analyses in R with the met- afor package. J Stat Softw. 2010;36(3):1-48. 17. Viechtbauer W. Bias and efficiency of meta-analytic variance estimators in the random-effects model. Journal of Educational and Behavioral Statistics. 2005;30(3):261-293. 18. Viechtbauer W, Lopez-Lopez JA, Sanchez-Meca J, Marín- Martínez F. A comparison of procedures to test for moderators in mixed-effects meta-regression models. Psychol Methods. 2015;20(3):360-374. 19. Nocedal J, Wright SJ. Numerical optimization. 2nd ed. Springer; 2006. 20. Harville DA. Maximum likelihood approaches to variance com- ponent estimation and to related problems. J Am Stat Assoc. 1977;72(358):320-338. 21. Patterson HD, Thompson R. Maximum likelihood estimation of components of variance. Proceedings of the 8th International Biometrics Conference; Biometric Society. 1974:197-207. 22. Corbeil RR, Searle SR. A comparison of variance component estimation. Biometrics. 1976;32(4):779-791. 23. Corbeil RR, Searle SR. Restricted maximum likelihood (REML) estimation of variance components in the mixed model. Dent Technometrics. 1976;18(1):31-38. 24. Press WH, Teukolsky SA, Vetterling WT, Flannery BP. Numeri- cal Recipes: the Art of Scientific Computing. 3rd ed. Cambridge University Press; 2007. 25. Hardy RJ, Thompson SG. A likelihood approach to meta- analysis with random effects. Stat Med. 1996;15(6):619-629. 26. Raudenbush SW. Analyzing effect sizes: random-effects models. In: Cooper H, Hedges LV, Valentine JC, eds. The Handbook of Research Synthesis and Meta-Analysis. 2nd ed. Russell Sage Foundation; 2009:295-315. 27. Konstantopoulos S, Hedges LV. Statistically analyzing effect sizes: fixed- and random-effects models. In: Cooper H, Hedges LV, Valentine JC, eds. The Handbook of Research Synthesis and Meta- Analysis. 3rd ed. Russell Sage Foundation; 2019:245-279. 28. Knapp G, Hartung J. Improved tests for a random effects meta- regression with a single covariate. Stat Med. 2003;22(17):2693- 2710. 29. Follmann DA, Proschan MA. Valid inference in random effects meta-analysis. Biometrics. 1999;55(3):732-737. 30. Berkey CS, Hoaglin DC, Mosteller F, Colditz GA. A random- effects regression model for meta-analysis. Stat Med. 1995; 14(4):395-411. 31. Viechtbauer W. Hypothesis tests for population heterogeneity in meta-analysis. British Journal of Mathematical and Statistical Psychology. 2007;60(1):29-60. 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License VIECHTBAUER AND LÓPEZ-LÓPEZ 32. Viechtbauer W. Confidence intervals for the amount of hetero- geneity in meta-analysis. Stat Med. 2007;26(1):37-52. 33. Raue A, Kreutz C, Maiwald T, et al. Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood. Bioinformatics. 2009;25(15): 1923-1929. 34. Hunter JE, Schmidt FL. Methods of Meta-Analysis: Correcting Error and Bias in Research Findings. Sage; 1990. 35. Higgins JPT, Thompson SG, Spiegelhalter DJ. A re-evaluation of random-effects meta-analysis. Journal of the Royal Statistical Society, Series A. 2009;172(1):137-159. 36. Borenstein M, Hedges LV, Higgins JPT, Rothstein HR. Intro- duction to Meta-Analysis. Wiley; 2009. 37. Kutner MH, Nachtsheim CJ, Neter J, Li W. Applied Linear Sta- tistical Models. 5th ed. McGraw-Hill; 2005. 38. Thompson SG, Higgins JPT. How should meta-regression analyses be undertaken and interpreted? Stat Med. 2002;21(11):1559-1573. 39. Anzures-Cabrera J, Higgins JPT. Graphical displays for meta- analysis: an overview with suggestions for practice. Res Synth Methods. 2010;1(1):66-80. 40. Cinar O, Umbanhowar J, Hoeksema JD, Viechtbauer W. Using information-theoretic approaches for model selection in meta- analysis. Res Synth Methods. 2021;12(4):537-556. 41. Tipton E, Pustejovsky JE, Ahmadi H. Current practices in meta-regression in psychology, education, and medicine. Res Synth Methods. 2019;10(2):180-194. 42. Lipsey MW. Those confounded moderators in meta-analysis: good, bad, and ugly. Ann Am Acad pol Soc Sci. 2003;587:69-81. 43. Burnham KP, Anderson DR. Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach. 2nd ed. Springer; 2002. 44. Akaike H. A new look at the statistical model identification. IEEE Transactions on Automatic Control. 1974;19(6):716-723. 45. Schwarz G. Estimating the dimension of a model. Annals of Statistics. 1978;6(2):461-464. 46. Hurvich CM, Tsai CL. Bias of the corrected AIC criterion for underfitted regression and time series models. Biometrika. 1991;78(3):499-509. 47. Pinheiro JC, Bates D. Mixed-Effects Models in S and S-PLUS. Springer; 2000. 48. Verbeke G, Molenberghs G. Linear Mixed Models for Longitudi- nal Data. Springer; 2000. 49. Gurka MJ. Selecting the best linear mixed model under REML. The American Statistician. 2006;60(1):19-26. 50. R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing; 2021. 51. Gay DM. Usage Summary for Selected Optimization Routines. Technical Report. AT&T Bell Laboratories; 1990. 52. Nelder JA, Mead R. A simplex method for function minimiza- tion. The Computer Journal. 1965;7(4):308-313. 53. Lange K. Numerical Analysis for Statisticians. Springer; 1999. 54. Gilbert P, Varadhan R. numDeriv: Accurate numerical deriva- tives. 2016. R package version 2016.8-1. 55. Bangert-Drowns RL, Hurley MM, Wilkinson B. The effects of school-based writing-to-learn interventions on academic achievement: a meta-analysis. Review of Educational Research. 2004;74(1):29-58. 56. Hedges LV, Olkin I. Statistical Methods for Meta-Analysis. Aca- demic Press; 1985. 715 57. Jackson D. Confidence intervals for the between-study variance in random effects meta-analysis using generalised Cochran het- erogeneity statistics. Res Synth Methods. 2013;4(3):220-229. 58. Viechtbauer W. Accounting for heterogeneity via random-effects models and moderator analyses in meta-analysis. Zeitschrift für Psychologie / Journal of Psychology. 2007;215(2):104-121. 59. Cooper HM. Research Synthesis and Meta-Analysis: A Step-by- Step Approach. 5th ed. Sage; 2017. 60. Fisher DJ, Copas AJ, Tierney JF, Parmar MK. A critical review of methods for the assessment of patient-level interactions in indi- vidual participant data meta-analysis of randomized trials, and guidance for practitioners. J Clin Epidemiol. 2011;64(9):949-967. 61. Nakagawa S, Poulin R, Mengersen K, et al. Meta-analysis of variation: ecological and evolutionary applications and beyond. Methods in Ecology and Evolution. 2015;6(2):143-152. 62. Prendergast LA, Staudte RG. Meta-analysis of ratios of sample variances. Stat Med. 2016;35(11):1780-1799. 63. Senior AM, Viechtbauer W, Nakagawa S. Revisiting and expan- ding the meta-analysis of variation: the log coefficient of varia- tion ratio. Res Synth Methods. 2020;11(4):553-567. 64. Alba AC, Alexander PE, Chang J, MacIsaac J, DeFry S, Guyatt GH. High statistical heterogeneity is more frequent in meta-analysis of continuous than binary outcomes. J Clin Epidemiol. 2016;70:129-135. 65. Rhodes KM, Turner RM, Higgins JP. Predictive distributionswere developed for the extent of heterogeneity in meta-analyses of con- tinuous outcome data. J Clin Epidemiol. 2015;68(1):52-60. 66. Rhodes KM, Turner RM, Higgins JP. Empirical evidence about inconsistency among studies in a pair-wise meta-analysis. Res Synth Methods. 2016;7(4):346-370. 67. Senior AM, Grueber CE, Kamiya T, et al. Heterogeneity in eco- logical and evolutionary meta-analyses: its magnitude and implications. Ecology. 2016;97(12):3293-3299. 68. Turner RM, Jackson D, Wei Y, Thompson SG, Higgins JP. Pre- dictive distributions for between-study heterogeneity and sim- ple methods for their application in Bayesian meta-analysis. Stat Med. 2015;34(6):984-998. 69. IntHout J, Ioannidis JPA, Borm GF, Goeman JJ. Small studies are more heterogeneous than large ones: a meta-metaanalysis. J Clin Epidemiol. 2015;68(8):860-869. 70. Kalaian HA, Raudenbush SW. A multivariate mixed linear model for meta-analysis. Psychol Methods. 1996;1(3):227-235. 71. Berkey CS, Hoaglin DC, Antczak-Bouckoms A, Mosteller F, Colditz GA. Meta-analysis of multiple outcomes by regression with random effects. Stat Med. 1998;17(22):2537-2550. 72. Gleser LJ, Olkin I. Stochastically dependent effect sizes. In: Cooper H, Hedges LV, Valentine JC, eds. The Handbook of Research Synthesis and Meta-Analysis. 2nd ed. Russell Sage Foundation; 2009:357-376. 73. Konstantopoulos S. Fixed effects and variance components estima- tion in three-level meta-analysis. Res Synth Methods. 2011;2(1):61-76. How to cite this article: Viechtbauer W, Lopez-Lopez JA. Location-scale models for meta- analysis. Res Syn Meth. 2022;13(6):697‐715. doi:10. 1002/jrsm.1562 17592887, 2022, 6, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562 by University Of Alberta, Wiley Online Library on \[08/12/2024\]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
